{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad71d264",
   "metadata": {},
   "source": [
    "# VQ-GANè®ºæ–‡é˜…è¯»+ä»£ç è§£æž\n",
    "\n",
    "> ç¬¬ä¸€æ¬¡å†™ï¼š0928\n",
    "> \n",
    "> ç¬¬äºŒæ¬¡è¡¥å……ï¼š 2025-10-08 19:09:54 Wednesday\n",
    "\n",
    "é‡è¦è§‚ç‚¹ï¼š\n",
    "1. **VQ-GANä¸­çš„Transformerå±žäºŽé€šé“æ³¨æ„åŠ›ç»“æž„**:å…¶è®¾è®¡èžåˆäº†CNNç‰¹å¾æå–çš„æ€æƒ³ã€‚æ³¨æ„åŠ›å¹¶éžç›´æŽ¥åœ¨åƒç´ å±‚é¢å±•å¼€ï¼Œè€Œæ˜¯åœ¨å·ç§¯ç½‘ç»œæå–çš„å¤šé€šé“ç‰¹å¾å›¾ä¸Šè¿›è¡Œå»ºæ¨¡ï¼Œä»Žè€Œåœ¨ä¿æŒå±€éƒ¨ç©ºé—´ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå¼•å…¥å…¨å±€ä¾èµ–å…³ç³»ã€‚\n",
    "\n",
    "2.  **VQ-GANèƒ½ä¿ç•™ä¸°å¯Œå›¾åƒä¿¡æ¯å¹¶å®žçŽ°é«˜è´¨é‡é‡å»ºçš„å…³é”®åœ¨äºŽå…¶tokenï¼ˆç æœ¬å‘é‡ï¼‰è®¾è®¡**:è¿™äº›ç¦»æ•£tokenå¹¶éžä»…è¡¨ç¤ºæŸä¸ªåƒç´ å—çš„é¢œè‰²ï¼Œè€Œæ˜¯é€šè¿‡å¤šå±‚å·ç§¯ç¼–ç å™¨ï¼ˆencoderï¼‰ä¸‹é‡‡æ ·åŽèŽ·å¾—çš„é«˜å±‚è¯­ä¹‰è¡¨å¾ï¼Œå› è€Œæ¯ä¸ªtokenéƒ½è•´å«å…¶é‚»åŸŸçš„ç»“æž„ä¸Žè¯­ä¹‰ä¸Šä¸‹æ–‡ã€‚è¿™ç§â€œä¸Šä¸‹æ–‡ä¸°å¯Œâ€çš„embedding tokenä½¿å¾—Transformeré˜¶æ®µèƒ½å¤Ÿç†è§£å…¨å±€ç‰©ä½“å½¢çŠ¶ã€è¾¹ç•Œä¸Žè¯­ä¹‰å…³ç³»ï¼Œä»Žè€Œåœ¨åˆæˆæ—¶ç”Ÿæˆç»“æž„ä¸€è‡´ã€å†…å®¹çœŸå®žçš„å›¾åƒã€‚\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290b7f6",
   "metadata": {},
   "source": [
    "## æ–‡ç« åŠ¨æœº\n",
    "\n",
    "ä¸ºäº†è§£å†³ Transformer **åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸçš„ä¸¤å¤§æ ¹æœ¬æ€§ç“¶é¢ˆ**ï¼šï¼Œè€Œæå‡ºå°†å·ç§¯ç½‘ç»œçš„é«˜æ•ˆå±€éƒ¨å»ºæ¨¡ä¸ŽTransformerçš„å¼ºå¤§å…¨å±€å»ºæ¨¡ç›¸ç»“åˆï¼Œä½¿Transformerèƒ½åœ¨é«˜åˆ†è¾¨çŽ‡å›¾åƒç”Ÿæˆä¸­æ—¢é«˜æ•ˆåˆå…·æœ‰å…¨å±€è¯­ä¹‰ä¸€è‡´æ€§ã€‚\n",
    "### **1ï¸âƒ£ ç“¶é¢ˆä¸€ï¼šåƒç´ çº§Transformerçš„å¤æ‚åº¦å¤ªé«˜**\n",
    "\n",
    "* ç›´æŽ¥åœ¨åƒç´ ç©ºé—´ä¸Šå¯¹å›¾åƒè¿›è¡Œè‡ªå›žå½’å»ºæ¨¡ï¼ˆå¦‚ PixelRNNã€Image Transformerï¼‰ä¼šå¯¼è‡´ï¼š\n",
    "  $$\\text{å¤æ‚åº¦} = O(H^2W^2)$$\n",
    "  ä¹Ÿå°±æ˜¯éšåˆ†è¾¨çŽ‡å¹³æ–¹çº§å¢žé•¿ã€‚\n",
    "* è¿™æ ·åœ¨é«˜åˆ†è¾¨çŽ‡ï¼ˆä¾‹å¦‚ 512Ã—512 ç”šè‡³æ›´å¤§ï¼‰æ—¶å‡ ä¹Žæ— æ³•è®­ç»ƒæˆ–é‡‡æ ·ã€‚\n",
    "\n",
    "\n",
    "### **2ï¸âƒ£ ç“¶é¢ˆäºŒï¼šåƒç´ ç¼ºä¹â€œä¸Šä¸‹æ–‡è¯­ä¹‰â€**\n",
    "\n",
    "* æ¯ä¸ªåƒç´ æˆ–å°patchç‹¬ç«‹ç¼–ç ï¼ŒTransformerè¦è‡ªå·±â€œå­¦ä¹ â€å…¨å±€ç»“æž„å’Œè¯­ä¹‰ï¼ˆæ¯”å¦‚ç‰©ä½“çš„å½¢çŠ¶ã€è½®å»“ï¼‰ï¼Œæ•ˆçŽ‡æžä½Žï¼›\n",
    "* ç¼ºä¹å½’çº³åç½®ï¼ˆinductive biasï¼‰ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€ç”Ÿæˆè´¨é‡ä½Žã€‚\n",
    "\n",
    "\n",
    "### ðŸ’¡ æå‡ºçš„æ–¹æ¡ˆ\n",
    "\n",
    "> **â€œè®©Transformerä¸å†ç›´æŽ¥çœ‹åƒç´ ï¼Œè€Œæ˜¯çœ‹è¯­ä¹‰tokenã€‚â€**\n",
    "\n",
    "* é€šè¿‡ **VQ-GAN** çš„ç¼–ç å™¨ï¼ˆCNNç»“æž„ï¼‰å…ˆå°†å›¾åƒåŽ‹ç¼©æˆ**ä¸Šä¸‹æ–‡ä¸°å¯Œçš„ç¦»æ•£token**ï¼ˆå³è§†è§‰è¯æ±‡è¡¨ä¸­çš„codeï¼‰ã€‚\n",
    "* è¿™äº›tokenä¸æ˜¯åŽŸå§‹åƒç´ ï¼Œè€Œæ˜¯èžåˆäº†å±€éƒ¨ç»“æž„ä¸Žè¯­ä¹‰çš„é«˜å±‚ç‰¹å¾ã€‚\n",
    "* æœ€åŽTransformerå¯ä»¥åˆ©ç”¨è¿™äº›**ä½Žç»´ã€è¯­ä¹‰åŒ–çš„tokenåºåˆ—**ä¸Šè¿›è¡Œè‡ªå›žå½’å»ºæ¨¡ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21cba9",
   "metadata": {},
   "source": [
    "## GroupNormï¼Ÿ\n",
    "\n",
    "- GroupNorm å°†è¾“å…¥ç‰¹å¾å›¾çš„é€šé“ï¼ˆChannelï¼‰åˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªå°ç»„ï¼ˆGroupï¼‰ï¼Œåœ¨æ¯ä¸ªå°ç»„å†…éƒ¨ç‹¬ç«‹è¿›è¡Œå½’ä¸€åŒ–æ“ä½œï¼ˆè®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼Œå¹¶é€šè¿‡ç¼©æ”¾å’Œå¹³ç§»è°ƒæ•´åˆ†å¸ƒï¼‰ã€‚\n",
    "- å¥½å¤„æ˜¯GroupNorm é€šè¿‡æŒ‰é€šé“åˆ†ç»„è¿›è¡Œå½’ä¸€åŒ–ï¼Œæ‘†è„±äº†å¯¹æ‰¹é‡å¤§å°çš„ä¾èµ–ï¼Œåœ¨å°æ‰¹é‡åœºæ™¯ä¸‹æ¯” BatchNorm æ›´é²æ£’ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed2e410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from icecream import ic\n",
    "def Normalize(in_channels, num_groups=32):\n",
    "    return torch.nn.GroupNorm(num_groups=num_groups, num_channels=in_channels, eps=1e-6, affine=True)\n",
    "\n",
    "\n",
    "def nonlinearity(x):\n",
    "    # swish\n",
    "    return x*torch.sigmoid(x)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if self.with_conv:\n",
    "            # no asymmetric padding in torch conv, must do it ourselves\n",
    "            self.conv = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=2,\n",
    "                                        padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.with_conv:\n",
    "            pad = (0,1,0,1)\n",
    "            x = torch.nn.functional.pad(x, pad, mode=\"constant\", value=0)\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        return x\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if self.with_conv:\n",
    "            self.conv = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n",
    "        if self.with_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590af6d",
   "metadata": {},
   "source": [
    "## é€šé“æ³¨æ„åŠ›\n",
    "\n",
    "**é€šé“æ³¨æ„åŠ›æ˜¯ä»€ä¹ˆ?**\n",
    "\n",
    "é€šé“æ³¨æ„åŠ›é€šè¿‡å¯¹å„é€šé“è¿›è¡ŒåŠ æƒç»„åˆï¼Œä»Žæ•´ä½“ä¸Šçªå‡ºé‡è¦é€šé“ã€æŠ‘åˆ¶æ¬¡è¦é€šé“ï¼›è‹¥ä»Žå•ä¸ªé€šé“è§’åº¦æ¥çœ‹ï¼Œå…¶æ•ˆæžœå¯ç­‰ä»·ä¸ºä¸€æ¬¡ä»¿å°„å˜æ¢ï¼ˆç¼©æ”¾ä¸Žå¹³ç§»ï¼‰ã€‚\n",
    "\n",
    "\n",
    "\n",
    "**ä¸åŒä»»åŠ¡ä¸‹çš„æ³¨æ„åŠ›æœºåˆ¶å«ä¹‰?**\n",
    "\n",
    "- NLP ä»»åŠ¡ï¼šä¸»è¦åœ¨åºåˆ—ç»´åº¦ä¸Šå»ºæ¨¡ï¼ˆè¯ä¸Žè¯ä¹‹é—´çš„å…³ç³»ï¼‰ï¼Œæ³¨æ„åŠ›æœºåˆ¶ç”¨äºŽçªå‡ºæ–‡æœ¬åºåˆ—ä¸­å…³é”®çš„ tokenã€‚\n",
    "\n",
    "- å›¾åƒä»»åŠ¡ï¼šæ³¨æ„åŠ›å¯ä»¥ä½œç”¨äºŽä¸åŒç»´åº¦\n",
    "    - é€šé“æ³¨æ„åŠ›ï¼šå¼ºè°ƒé‡è¦é€šé“çš„ä¿¡æ¯ï¼ŒæŠ‘åˆ¶æ¬¡è¦é€šé“ã€‚\n",
    "    - ç©ºé—´æ³¨æ„åŠ›ï¼šçªå‡ºä¸åŒ patch æˆ–åƒç´ çš„ä½ç½®é‡è¦æ€§ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**ä½ç½®ç¼–ç é—®é¢˜**\n",
    "\n",
    "- æ–‡æœ¬æ³¨æ„åŠ›ï¼šä¸€ç»´ä½ç½®ç¼–ç æ˜¯å¿…é¡»çš„ï¼Œç”¨äºŽä¿ç•™åºåˆ—é¡ºåºä¿¡æ¯ã€‚\n",
    "\n",
    "- å›¾åƒç©ºé—´æ³¨æ„åŠ›ï¼šäºŒç»´ä½ç½®ç¼–ç é€šå¸¸æ˜¯å¿…é¡»çš„ï¼Œå°¤å…¶åœ¨å…¨å±€æ³¨æ„åŠ›æˆ– Transformer æž¶æž„ä¸­ï¼Œç”¨äºŽä¿ç•™åƒç´ æˆ– patch çš„ç©ºé—´å…³ç³»ã€‚\n",
    "\n",
    "- å›¾åƒé€šé“æ³¨æ„åŠ›ï¼šè¾“å…¥é€šå¸¸æ˜¯ç»è¿‡å·ç§¯æå–çš„ç‰¹å¾å›¾ï¼Œå·²ç»éšå«ç©ºé—´ä¿¡æ¯ï¼Œå› æ­¤ä¸éœ€è¦é¢å¤–çš„ä½ç½®ç¼–ç ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ab95ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mw_\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mout\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 16, 16])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch_diffusion + derived encoder decoder\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.norm = Normalize(in_channels)\n",
    "        self.q = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.k = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.v = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.proj_out = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=1,\n",
    "                                        stride=1,\n",
    "                                        padding=0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = x\n",
    "        h_ = self.norm(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "        ic(q.shape)\n",
    "\n",
    "        # compute attention\n",
    "        b,c,h,w = q.shape\n",
    "        q = q.reshape(b,c,h*w)\n",
    "        q = q.permute(0,2,1)   # b,hw,c\n",
    "        k = k.reshape(b,c,h*w) # b,c,hw\n",
    "        ic(q.shape)\n",
    "        w_ = torch.bmm(q,k)     # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]\n",
    "        ic(w_.shape)\n",
    "        w_ = w_ * (int(c)**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_, dim=2)\n",
    "\n",
    "        # attend to values\n",
    "        v = v.reshape(b,c,h*w)\n",
    "        w_ = w_.permute(0,2,1)   # b,hw,hw (first hw of k, second of q)\n",
    "        h_ = torch.bmm(v,w_)     # b, c,hw (hw of q) h_[b,c,j] = sum_i v[b,c,i] w_[b,i,j]\n",
    "        h_ = h_.reshape(b,c,h,w)\n",
    "\n",
    "        h_ = self.proj_out(h_)\n",
    "\n",
    "        return x+h_\n",
    "\n",
    "\n",
    "\n",
    "def make_attn(in_channels, attn_type=\"vanilla\"):\n",
    "    assert attn_type in [\"vanilla\", \"linear\", \"none\"], f'attn_type {attn_type} unknown'\n",
    "    print(f\"making attention of type '{attn_type}' with {in_channels} in_channels\")\n",
    "    if attn_type == \"vanilla\":\n",
    "        return AttnBlock(in_channels)\n",
    "    elif attn_type == \"none\":\n",
    "        return nn.Identity(in_channels)\n",
    "    else:\n",
    "        return LinAttnBlock(in_channels)\n",
    "\n",
    "\n",
    "img=torch.rand(2,512,16,16)\n",
    "attn=AttnBlock(img.shape[1])\n",
    "\n",
    "out=attn(img)\n",
    "ic(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a35f6",
   "metadata": {},
   "source": [
    "## æ®‹å·®ç½‘ç»œå—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7140a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False,\n",
    "                 dropout, temb_channels=512):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        out_channels = in_channels if out_channels is None else out_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_conv_shortcut = conv_shortcut\n",
    "\n",
    "        self.norm1 = Normalize(in_channels)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1,\n",
    "                                     padding=1)\n",
    "        if temb_channels > 0:\n",
    "            self.temb_proj = torch.nn.Linear(temb_channels,\n",
    "                                             out_channels)\n",
    "        self.norm2 = Normalize(out_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1,\n",
    "                                     padding=1)\n",
    "        if self.in_channels != self.out_channels:\n",
    "            if self.use_conv_shortcut:\n",
    "                self.conv_shortcut = torch.nn.Conv2d(in_channels,\n",
    "                                                     out_channels,\n",
    "                                                     kernel_size=3,\n",
    "                                                     stride=1,\n",
    "                                                     padding=1)\n",
    "            else:\n",
    "                self.nin_shortcut = torch.nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=1,\n",
    "                                                    padding=0)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = x\n",
    "        h = self.norm1(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        if temb is not None:\n",
    "            h = h + self.temb_proj(nonlinearity(temb))[:,:,None,None]\n",
    "\n",
    "        h = self.norm2(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if self.in_channels != self.out_channels:\n",
    "            if self.use_conv_shortcut:\n",
    "                x = self.conv_shortcut(x)\n",
    "            else:\n",
    "                x = self.nin_shortcut(x)\n",
    "\n",
    "        return x+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "160753d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_diffusion + derived encoder decoder\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.norm = Normalize(in_channels)\n",
    "        self.q = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.k = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.v = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.proj_out = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=1,\n",
    "                                        stride=1,\n",
    "                                        padding=0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = x\n",
    "        h_ = self.norm(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "\n",
    "        # compute attention\n",
    "        b,c,h,w = q.shape\n",
    "        q = q.reshape(b,c,h*w)\n",
    "        q = q.permute(0,2,1)   # b,hw,c\n",
    "        k = k.reshape(b,c,h*w) # b,c,hw\n",
    "        w_ = torch.bmm(q,k)     # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]\n",
    "        w_ = w_ * (int(c)**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_, dim=2)\n",
    "\n",
    "        # attend to values\n",
    "        v = v.reshape(b,c,h*w)\n",
    "        w_ = w_.permute(0,2,1)   # b,hw,hw (first hw of k, second of q)\n",
    "        h_ = torch.bmm(v,w_)     # b, c,hw (hw of q) h_[b,c,j] = sum_i v[b,c,i] w_[b,i,j]\n",
    "        h_ = h_.reshape(b,c,h,w)\n",
    "\n",
    "        h_ = self.proj_out(h_)\n",
    "\n",
    "        return x+h_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98356c8d",
   "metadata": {},
   "source": [
    "## Encoderç½‘ç»œç»“æž„æž„æˆ\n",
    "\n",
    "\n",
    "1. å°†è¾“å…¥å›¾ç‰‡è½¬æˆç­‰å¤§å°å¤šé€šé“çš„åˆå§‹ç‰¹å¾å›¾ï¼ˆé€šé“æ•°:ch=128ï¼‰\n",
    "2. ä¸‹é‡‡æ ·é˜¶æ®µï¼Œ\n",
    "    - åŒ…å«3ä¸ªå­é˜¶æ®µï¼Œæ¯ä¸ªå­é˜¶æ®µçš„é€šé“æ•°ä¸ºch_mult[i]*chï¼Œæ¯æ¬¡åˆ†è¾¨çŽ‡ä¸‹é™1å€\n",
    "    - å³chu_mult: [1,2,4]ï¼Œåˆ™é€šé“æ•°å˜åŒ–ï¼šch=128->128->256->512\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acf8bc19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mattn_type\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mvanilla\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi_level\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m0\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247min_ch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mnum_res_blocks\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi_level\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247min_ch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mnum_res_blocks\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi_level\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247min_ch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mnum_res_blocks\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mdown\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdownsample\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDownsample\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnin_shortcut\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdownsample\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDownsample\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnin_shortcut\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m               \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mmid\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock_1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn_1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mAttnBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mk\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mv\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mproj_out\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock_2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mconv_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mh\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mw_\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *, ch=1, out_ch=3, ch_mult=(1,2,4,8), num_res_blocks=2,\n",
    "                 attn_resolutions=1, dropout=0.0, resamp_with_conv=True, in_channels=2,\n",
    "                 resolution=1, z_channels=2, double_z=True, use_linear_attn=False, attn_type=\"vanilla\",\n",
    "                 **ignore_kwargs):\n",
    "        super().__init__()\n",
    "        if use_linear_attn: attn_type = \"linear\"\n",
    "        ic(attn_type)\n",
    "        self.ch = ch\n",
    "        self.temb_ch = 0\n",
    "        self.num_resolutions = len(ch_mult)\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.resolution = resolution\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # downsampling\n",
    "        self.conv_in = torch.nn.Conv2d(in_channels,\n",
    "                                       self.ch,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1)\n",
    "\n",
    "        curr_res = resolution\n",
    "        in_ch_mult = (1,)+tuple(ch_mult)\n",
    "        self.in_ch_mult = in_ch_mult\n",
    "        self.down = nn.ModuleList()\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_in = ch*in_ch_mult[i_level]\n",
    "            block_out = ch*ch_mult[i_level]\n",
    "            ic(i_level)\n",
    "            ic(block_in)\n",
    "            ic(block_out)\n",
    "            ic(in_ch_mult,ch_mult)\n",
    "            ic(self.num_res_blocks)\n",
    "            \n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                block.append(ResnetBlock(in_channels=block_in,\n",
    "                                         out_channels=block_out,\n",
    "                                         temb_channels=self.temb_ch,\n",
    "                                         dropout=dropout))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(make_attn(block_in, attn_type=attn_type))\n",
    "            down = nn.Module()\n",
    "            down.block = block\n",
    "            down.attn = attn\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                down.downsample = Downsample(block_in, resamp_with_conv)\n",
    "                curr_res = curr_res // 2\n",
    "            self.down.append(down)\n",
    "        ic(self.down)\n",
    "\n",
    "        # middle\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        ic(block_in)\n",
    "        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n",
    "        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        \n",
    "        ic(self.mid)\n",
    "\n",
    "        # end\n",
    "        self.norm_out = Normalize(block_in)\n",
    "        self.conv_out = torch.nn.Conv2d(block_in,\n",
    "                                        2*z_channels if double_z else z_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "        ic(self.conv_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # timestep embedding\n",
    "        temb = None\n",
    "\n",
    "        # downsampling\n",
    "        hs = [self.conv_in(x)]\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                h = self.down[i_level].block[i_block](hs[-1], temb)\n",
    "                if len(self.down[i_level].attn) > 0:\n",
    "                    h = self.down[i_level].attn[i_block](h)\n",
    "                hs.append(h)\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                hs.append(self.down[i_level].downsample(hs[-1]))\n",
    "\n",
    "        # middle\n",
    "        h = hs[-1]\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        ic(h.shape)\n",
    "        h = self.mid.attn_1(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "\n",
    "        # end\n",
    "        h = self.norm_out(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv_out(h)\n",
    "        return h\n",
    "\n",
    "ddconfig = {\n",
    "    \"double_z\": False,\n",
    "    \"z_channels\": 3,\n",
    "    \"resolution\": 64,\n",
    "    \"in_channels\": 1,\n",
    "    \"out_ch\": 1,\n",
    "    \"ch\": 128,\n",
    "    \"ch_mult\": [1, 2, 4],\n",
    "    \"num_res_blocks\": 3,\n",
    "    \"attn_resolutions\": [],\n",
    "    \"dropout\": 0.0\n",
    "}\n",
    "\n",
    "encoder=Encoder(**ddconfig)\n",
    "\n",
    "random_input = torch.randn(2, ddconfig[\"in_channels\"], ddconfig[\"resolution\"], ddconfig[\"resolution\"])\n",
    "\n",
    "# å‰å‘ä¼ æ’­\n",
    "output = encoder(random_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6a08b",
   "metadata": {},
   "source": [
    "## Decoderç½‘ç»œæž„æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ace6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 3, 16, 16) = 768 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n",
    "                 attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n",
    "                 resolution, z_channels, give_pre_end=False, tanh_out=False, use_linear_attn=False,\n",
    "                 attn_type=\"vanilla\", **ignorekwargs):\n",
    "        super().__init__()\n",
    "        if use_linear_attn: attn_type = \"linear\"\n",
    "        self.ch = ch\n",
    "        self.temb_ch = 0\n",
    "        self.num_resolutions = len(ch_mult)\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.resolution = resolution\n",
    "        self.in_channels = in_channels\n",
    "        self.give_pre_end = give_pre_end\n",
    "        self.tanh_out = tanh_out\n",
    "\n",
    "        # compute in_ch_mult, block_in and curr_res at lowest res\n",
    "        in_ch_mult = (1,)+tuple(ch_mult)\n",
    "        block_in = ch*ch_mult[self.num_resolutions-1]\n",
    "        curr_res = resolution // 2**(self.num_resolutions-1)\n",
    "        self.z_shape = (1,z_channels,curr_res,curr_res)\n",
    "        print(\"Working with z of shape {} = {} dimensions.\".format(\n",
    "            self.z_shape, np.prod(self.z_shape)))\n",
    "\n",
    "        # z to block_in\n",
    "        self.conv_in = torch.nn.Conv2d(z_channels,\n",
    "                                       block_in,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1)\n",
    "\n",
    "        # middle\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n",
    "        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "\n",
    "        # upsampling\n",
    "        self.up = nn.ModuleList()\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_out = ch*ch_mult[i_level]\n",
    "            for i_block in range(self.num_res_blocks+1):\n",
    "                block.append(ResnetBlock(in_channels=block_in,\n",
    "                                         out_channels=block_out,\n",
    "                                         temb_channels=self.temb_ch,\n",
    "                                         dropout=dropout))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(make_attn(block_in, attn_type=attn_type))\n",
    "            up = nn.Module()\n",
    "            up.block = block\n",
    "            up.attn = attn\n",
    "            if i_level != 0:\n",
    "                up.upsample = Upsample(block_in, resamp_with_conv)\n",
    "                curr_res = curr_res * 2\n",
    "            self.up.insert(0, up) # prepend to get consistent order\n",
    "\n",
    "        # end\n",
    "        self.norm_out = Normalize(block_in)\n",
    "        self.conv_out = torch.nn.Conv2d(block_in,\n",
    "                                        out_ch,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        #assert z.shape[1:] == self.z_shape[1:]\n",
    "        self.last_z_shape = z.shape\n",
    "\n",
    "        # timestep embedding\n",
    "        temb = None\n",
    "\n",
    "        # z to block_in\n",
    "        h = self.conv_in(z)\n",
    "\n",
    "        # middle\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        h = self.mid.attn_1(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "\n",
    "        # upsampling\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            for i_block in range(self.num_res_blocks+1):\n",
    "                h = self.up[i_level].block[i_block](h, temb)\n",
    "                if len(self.up[i_level].attn) > 0:\n",
    "                    h = self.up[i_level].attn[i_block](h)\n",
    "            if i_level != 0:\n",
    "                h = self.up[i_level].upsample(h)\n",
    "\n",
    "        # end\n",
    "        if self.give_pre_end:\n",
    "            return h\n",
    "\n",
    "        h = self.norm_out(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv_out(h)\n",
    "        if self.tanh_out:\n",
    "            h = torch.tanh(h)\n",
    "        return h\n",
    "\n",
    "decoder=Decoder(**ddconfig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bc591",
   "metadata": {},
   "source": [
    "## å‘é‡é‡åŒ–å™¨ä»¥åŠé‡åŒ–æŸå¤± $\\mathcal{L}_{codebook}$\n",
    "\n",
    "æ¥è‡ª `VectorQuantizer2.forward()`ï¼š\n",
    "\n",
    "```python\n",
    "if not self.legacy:\n",
    "    loss = self.beta * torch.mean((z_q.detach()-z)**2) + \\\n",
    "           torch.mean((z_q - z.detach()) ** 2)\n",
    "else:\n",
    "    loss = torch.mean((z_q.detach()-z)**2) + \\\n",
    "           self.beta * torch.mean((z_q - z.detach()) ** 2)\n",
    "```\n",
    "\n",
    "### VQ-VAE çš„æ ¸å¿ƒï¼š\n",
    "å°† encoder è¾“å‡º ($z_e(x)$) æ›¿æ¢ä¸ºæœ€é‚»è¿‘çš„ codebook å‘é‡ ($e_k$)ã€‚\n",
    "\n",
    "\n",
    "$$\\mathcal{L}_{codebook} =\n",
    "| \\text{sg}[z_e(x)] - e_k |_2^2 +\n",
    "\\beta | z_e(x) - \\text{sg}[e_k] |_2^2$$\n",
    "\n",
    "å…¶ä¸­ `sg[Â·]` è¡¨ç¤º **stop-gradient**ï¼Œé˜²æ­¢æ¢¯åº¦æµåˆ°è¯¥é¡¹ã€‚\n",
    "ç¬¬ä¸€é¡¹æ›´æ–° codebook embeddingï¼›\n",
    "ç¬¬äºŒé¡¹æ›´æ–° encoderï¼Œè®©å…¶é è¿‘æœ€è¿‘çš„ embeddingã€‚\n",
    "\n",
    "### ðŸ§© Trick: Straight-Through Estimator (STE)\n",
    "\n",
    "```python\n",
    "z_q = z + (z_q - z).detach()\n",
    "```\n",
    "\n",
    "è¿™è¡Œæ˜¯ **ç›´é€šæ¢¯åº¦ä¼°è®¡**ï¼š\n",
    "\n",
    "* å‰å‘ï¼šè¾“å‡º (z_q)\n",
    "* åå‘ï¼šæ¢¯åº¦ç›´æŽ¥ä¼ å›ž (z)ï¼Œç»•è¿‡ç¦»æ•£é‡åŒ–æ“ä½œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2efe29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VectorQuantizer2(nn.Module):\n",
    "    \"\"\"\n",
    "    Improved version over VectorQuantizer, can be used as a drop-in replacement. Mostly\n",
    "    avoids costly matrix multiplications and allows for post-hoc remapping of indices.\n",
    "    \"\"\"\n",
    "    # NOTE: due to a bug the beta term was applied to the wrong term. for\n",
    "    # backwards compatibility we use the buggy version by default, but you can\n",
    "    # specify legacy=False to fix it.\n",
    "    def __init__(self, n_e, e_dim, beta, remap=None, unknown_index=\"random\",\n",
    "                 sane_index_shape=False, legacy=True):\n",
    "        super().__init__()\n",
    "        self.n_e = n_e\n",
    "        self.e_dim = e_dim\n",
    "        self.beta = beta\n",
    "        self.legacy = legacy\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_e, self.e_dim)\n",
    "        self.embedding.weight.data.uniform_(-1.0 / self.n_e, 1.0 / self.n_e)\n",
    "\n",
    "        self.remap = remap\n",
    "        if self.remap is not None:\n",
    "            self.register_buffer(\"used\", torch.tensor(np.load(self.remap)))\n",
    "            self.re_embed = self.used.shape[0]\n",
    "            self.unknown_index = unknown_index # \"random\" or \"extra\" or integer\n",
    "            if self.unknown_index == \"extra\":\n",
    "                self.unknown_index = self.re_embed\n",
    "                self.re_embed = self.re_embed+1\n",
    "            print(f\"Remapping {self.n_e} indices to {self.re_embed} indices. \"\n",
    "                  f\"Using {self.unknown_index} for unknown indices.\")\n",
    "        else:\n",
    "            self.re_embed = n_e\n",
    "\n",
    "        self.sane_index_shape = sane_index_shape\n",
    "\n",
    "    def remap_to_used(self, inds):\n",
    "        ishape = inds.shape\n",
    "        assert len(ishape)>1\n",
    "        inds = inds.reshape(ishape[0],-1)\n",
    "        used = self.used.to(inds)\n",
    "        match = (inds[:,:,None]==used[None,None,...]).long()\n",
    "        new = match.argmax(-1)\n",
    "        unknown = match.sum(2)<1\n",
    "        if self.unknown_index == \"random\":\n",
    "            new[unknown]=torch.randint(0,self.re_embed,size=new[unknown].shape).to(device=new.device)\n",
    "        else:\n",
    "            new[unknown] = self.unknown_index\n",
    "        return new.reshape(ishape)\n",
    "\n",
    "    def unmap_to_all(self, inds):\n",
    "        ishape = inds.shape\n",
    "        assert len(ishape)>1\n",
    "        inds = inds.reshape(ishape[0],-1)\n",
    "        used = self.used.to(inds)\n",
    "        if self.re_embed > self.used.shape[0]: # extra token\n",
    "            inds[inds>=self.used.shape[0]] = 0 # simply set to zero\n",
    "        back=torch.gather(used[None,:][inds.shape[0]*[0],:], 1, inds)\n",
    "        return back.reshape(ishape)\n",
    "\n",
    "    def forward(self, z, temp=None, rescale_logits=False, return_logits=False):\n",
    "        assert temp is None or temp==1.0, \"Only for interface compatible with Gumbel\"\n",
    "        assert rescale_logits==False, \"Only for interface compatible with Gumbel\"\n",
    "        assert return_logits==False, \"Only for interface compatible with Gumbel\"\n",
    "        # reshape z -> (batch, height, width, channel) and flatten\n",
    "        z = rearrange(z, 'b c h w -> b h w c').contiguous()\n",
    "        z_flattened = z.view(-1, self.e_dim)\n",
    "        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n",
    "\n",
    "        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n",
    "            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n",
    "            torch.einsum('bd,dn->bn', z_flattened, rearrange(self.embedding.weight, 'n d -> d n'))\n",
    "\n",
    "        min_encoding_indices = torch.argmin(d, dim=1)\n",
    "        z_q = self.embedding(min_encoding_indices).view(z.shape)\n",
    "        perplexity = None\n",
    "        min_encodings = None\n",
    "\n",
    "        # compute loss for embedding\n",
    "        if not self.legacy:\n",
    "            loss = self.beta * torch.mean((z_q.detach()-z)**2) + \\\n",
    "                   torch.mean((z_q - z.detach()) ** 2)\n",
    "        else:\n",
    "            loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n",
    "                   torch.mean((z_q - z.detach()) ** 2)\n",
    "\n",
    "        # preserve gradients\n",
    "        z_q = z + (z_q - z).detach()\n",
    "\n",
    "        # reshape back to match original input shape\n",
    "        z_q = rearrange(z_q, 'b h w c -> b c h w').contiguous()\n",
    "\n",
    "        if self.remap is not None:\n",
    "            min_encoding_indices = min_encoding_indices.reshape(z.shape[0],-1) # add batch axis\n",
    "            min_encoding_indices = self.remap_to_used(min_encoding_indices)\n",
    "            min_encoding_indices = min_encoding_indices.reshape(-1,1) # flatten\n",
    "\n",
    "        if self.sane_index_shape:\n",
    "            min_encoding_indices = min_encoding_indices.reshape(\n",
    "                z_q.shape[0], z_q.shape[2], z_q.shape[3])\n",
    "\n",
    "        return z_q, loss, (perplexity, min_encodings, min_encoding_indices)\n",
    "\n",
    "    def get_codebook_entry(self, indices, shape):\n",
    "        # shape specifying (batch, height, width, channel)\n",
    "        if self.remap is not None:\n",
    "            indices = indices.reshape(shape[0],-1) # add batch axis\n",
    "            indices = self.unmap_to_all(indices)\n",
    "            indices = indices.reshape(-1) # flatten again\n",
    "\n",
    "        # get quantized latent vectors\n",
    "        z_q = self.embedding(indices)\n",
    "\n",
    "        if shape is not None:\n",
    "            z_q = z_q.view(shape)\n",
    "            # reshape back to match original input shape\n",
    "            z_q = z_q.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        return z_q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28669f2",
   "metadata": {},
   "source": [
    "\n",
    "## VQ-GANçš„æŸå¤±å‡½æ•° (ä»£ç å®žçŽ°ä¸ºVQLPIPSWithDiscriminatorç±»)\n",
    "è¿™ä¸ªç±»å®žçŽ°çš„æ­£æ˜¯ VQ-GAN è®ºæ–‡ä¸­çš„æŸå¤±ç»“æž„ï¼š\n",
    "$$\\mathcal{L}*{total} = \\mathcal{L}*{rec/perceptual} + \\lambda \\mathcal{L}*{GAN} + \\beta \\mathcal{L}*{codebook}$$\n",
    "å¹¶é€šè¿‡è‡ªé€‚åº”æƒé‡ Î» å¹³è¡¡é‡å»ºä¸Žå¯¹æŠ—ä¸¤éƒ¨åˆ†çš„æ¢¯åº¦å¼ºåº¦ã€‚\n",
    "\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "  * **$\\mathcal{L}_{rec}$**ï¼šé‡å»ºæŸå¤±ï¼ˆåƒç´  + æ„ŸçŸ¥æŸå¤±ï¼‰\n",
    "  * **$\\mathcal{L}_{GAN}$**ï¼šå¯¹æŠ—æŸå¤±ï¼ˆç”Ÿæˆå™¨éƒ¨åˆ†ï¼‰\n",
    "  * **$\\mathcal{L}_{codebook}$**ï¼šé‡åŒ–æŸå¤±ï¼ˆcodebook embedding æ›´æ–°ï¼‰\n",
    "  * **$\\lambda$**ï¼šè‡ªé€‚åº”å¹³è¡¡æƒé‡ï¼ˆæ¢¯åº¦èŒƒæ•°æ¯”ï¼‰\n",
    "  * **$\\beta$**ï¼šVQ ä¸­æŽ§åˆ¶ embedding æ›´æ–°çš„æ¯”ä¾‹å› å­\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§± 1. æ¨¡åž‹ç»“æž„ç»„æˆ\n",
    "\n",
    "| æ¨¡å—              | å«ä¹‰                                  |\n",
    "| --------------- | ----------------------------------- |\n",
    "| `E` / `G` / `Z` | åˆ†åˆ«æ˜¯ encoderã€decoderã€codebook        |\n",
    "| `D`             | åˆ¤åˆ«å™¨ï¼ˆPatchGAN ç±»åž‹ï¼‰                    |\n",
    "| `LPIPS`         | æ„ŸçŸ¥æŸå¤±ï¼ˆperceptual lossï¼‰ï¼Œä½¿ç”¨é¢„è®­ç»ƒç½‘ç»œè®¡ç®—ç‰¹å¾å·®å¼‚ |\n",
    "| `codebook_loss` | ç æœ¬é‡åŒ–æŸå¤±ï¼ˆcommitment + embeddingï¼‰      |\n",
    "| `disc_loss`     | å¯¹æŠ—æŸå¤±ï¼Œå¯é€‰ \"hinge\" æˆ– \"vanilla\"         |\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ 2. æ€»ä½“å‰å‘é€»è¾‘\n",
    "\n",
    "åœ¨ `forward()` ä¸­æ ¹æ® `optimizer_idx` åˆ†ä¸ºä¸¤æ­¥ï¼š\n",
    "\n",
    "1. `optimizer_idx == 0`ï¼šæ›´æ–°ç”Ÿæˆå™¨ï¼ˆE, G, Zï¼‰\n",
    "2. `optimizer_idx == 1`ï¼šæ›´æ–°åˆ¤åˆ«å™¨ D\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§© 3. é‡å»º + æ„ŸçŸ¥æŸå¤±ï¼ˆReconstruction + Perceptualï¼‰\n",
    "\n",
    "```python\n",
    "rec_loss = torch.abs(inputs - reconstructions)\n",
    "p_loss = self.perceptual_loss(inputs, reconstructions)\n",
    "rec_loss = rec_loss + self.perceptual_weight * p_loss\n",
    "nll_loss = torch.mean(rec_loss)\n",
    "```\n",
    "\n",
    "å¯¹åº”å…¬å¼ï¼š\n",
    "\n",
    "$$\\mathcal{L}_{rec/perceptual} =\n",
    "\\mathbb{E}[|x - \\hat{x}|_1] +\n",
    "\\lambda_p |\\phi(x) - \\phi(\\hat{x})|_2^2$$\n",
    "\n",
    "* `L1` æ›¿ä»£äº†åƒç´ çº§ L2ï¼Œæ›´é²æ£’ï¼›\n",
    "* `LPIPS` æä¾›æ„ŸçŸ¥å±‚é¢çš„ç‰¹å¾è·ç¦»ï¼›\n",
    "* `perceptual_weight` æŽ§åˆ¶æ„ŸçŸ¥æŸå¤±çš„æƒé‡ï¼›\n",
    "* `nll_loss` ç›¸å½“äºŽ Eq.(6) ä¸­çš„ ($\\mathcal{L}_{rec}$)ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§® 4. Codebook é‡åŒ–æŸå¤±\n",
    "\n",
    "åœ¨ VQ-VAE/VQ-GAN ä¸­ï¼š\n",
    "\n",
    "$$\\mathcal{L}_{codebook} = |\\text{sg}[E(x)] - z_q|^2 + |E(x) - \\text{sg}[z_q]|^2$$\n",
    "\n",
    "è¿™é‡Œåœ¨æ€»æŸå¤±ä¸­ä½“çŽ°ä¸ºï¼š\n",
    "\n",
    "```python\n",
    "loss += self.codebook_weight * codebook_loss.mean()\n",
    "```\n",
    "\n",
    "è¡¨ç¤º â€œä¿æŒç¼–ç å™¨ä¸Žç æœ¬ä¸€è‡´æ€§â€ çš„çº¦æŸé¡¹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ­ 5. å¯¹æŠ—æŸå¤±ï¼ˆAdversarial Lossï¼‰\n",
    "\n",
    "#### âž¤ Generatorï¼ˆæ›´æ–°ç”Ÿæˆå™¨æ—¶ï¼‰\n",
    "  ```python\n",
    "  logits_fake = self.discriminator(reconstructions)\n",
    "  g_loss = -torch.mean(logits_fake)\n",
    "  ```\n",
    "  * å¯¹åº” **hinge-GAN ç”Ÿæˆå™¨æŸå¤±**ï¼š\n",
    "    $$\\mathcal{L}_G = -\\mathbb{E}[D(\\hat{x})]$$\n",
    "  * å³å¸Œæœ›ç”Ÿæˆå›¾åƒçš„åˆ¤åˆ«å¾—åˆ†é«˜ï¼ˆéª—è¿‡ Dï¼‰ã€‚\n",
    "\n",
    "#### âž¤ Discriminatorï¼ˆæ›´æ–°åˆ¤åˆ«å™¨æ—¶ï¼‰\n",
    "\n",
    "  ```python\n",
    "  logits_real = self.discriminator(inputs.detach())\n",
    "  logits_fake = self.discriminator(reconstructions.detach())\n",
    "  d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n",
    "  ```\n",
    "\n",
    "* å¯¹åº” **hinge-GAN åˆ¤åˆ«å™¨æŸå¤±**ï¼š\n",
    "  $$\\mathcal{L}_D =\n",
    "  \\mathbb{E}[\\max(0, 1 - D(x))] + \\mathbb{E}[\\max(0, 1 + D(\\hat{x}))]$$\n",
    "\n",
    "* è‹¥ä¸º vanilla-GANï¼Œåˆ™æ¢ä¸ºï¼š\n",
    "  $$\\mathcal{L}_D = -[\\log D(x) + \\log(1 - D(\\hat{x}))]$$\n",
    "\n",
    "---\n",
    "\n",
    "### âš–ï¸ 6. è‡ªé€‚åº”æƒé‡ Î»ï¼ˆAdaptive Weightï¼‰\n",
    "\n",
    "```python\n",
    "d_weight = self.calculate_adaptive_weight(nll_loss, g_loss, last_layer)\n",
    "```\n",
    "\n",
    "å…¬å¼å¯¹åº” Eq.(7)ï¼š\n",
    "\n",
    "$$\\lambda = \\frac{|\\nabla_{G_L}[\\mathcal{L}*{rec}]|}\n",
    "{|\\nabla*{G_L}[\\mathcal{L}_{GAN}]| + \\delta}$$\n",
    "\n",
    "å®žçŽ°æŠ€å·§ï¼š\n",
    "\n",
    "* é€šè¿‡ `torch.autograd.grad` å¯¹æœ€åŽä¸€å±‚æ¢¯åº¦å–èŒƒæ•°ï¼›\n",
    "* é¿å…é™¤é›¶ï¼Œç”¨ `+ 1e-4`ï¼›\n",
    "* `torch.clamp()` é™åˆ¶èŒƒå›´ï¼›\n",
    "* æœ€åŽä¹˜ä¸Š `self.discriminator_weight`ï¼ˆæ•´ä½“ç¼©æ”¾å› å­ï¼‰ã€‚\n",
    "\n",
    "**æ„ä¹‰ï¼š**\n",
    "\n",
    "* è‹¥ GAN è®­ç»ƒå¤ªå¼ºï¼ˆæ¢¯åº¦å¤§ï¼‰â†’ å‡å° Î»ï¼›\n",
    "* è‹¥é‡å»ºä¿¡å·å¼º â†’ å¢žå¤§ Î»ï¼›\n",
    "* ä¿è¯è®­ç»ƒç¨³å®šã€è§†è§‰è´¨é‡ä¸Žç»“æž„ä¿çœŸå…¼é¡¾ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  7. åˆ¤åˆ«å™¨å»¶è¿Ÿå¯ç”¨æŠ€å·§\n",
    "\n",
    "```python\n",
    "disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n",
    "```\n",
    "\n",
    "å®žçŽ°ç»†èŠ‚ï¼š\n",
    "\n",
    "* è®­ç»ƒåˆæœŸä¸å¯ç”¨åˆ¤åˆ«å™¨ï¼ˆé˜²æ­¢ GAN ä¸ç¨³å®šï¼‰ï¼›\n",
    "* å½“ `global_step > disc_start` åŽå†æ¿€æ´»ï¼›\n",
    "* ç›¸å½“äºŽè®ºæ–‡ä¸­çš„ â€œwarm-upâ€ ç­–ç•¥ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§¾ 8. æ€»æŸå¤±è¡¨è¾¾å¼ï¼ˆGeneratoré˜¶æ®µï¼‰\n",
    "\n",
    "$$\\mathcal{L}*{total} =\n",
    "\\underbrace{\\mathcal{L}*{rec/perceptual}}*{\\text{é‡å»º+æ„ŸçŸ¥}}+\n",
    "\\underbrace{d*{weight} \\cdot disc_{factor} \\cdot \\mathcal{L}*{GAN}}*{\\text{å¯¹æŠ—é¡¹}}\n",
    "+\\underbrace{\\beta \\cdot \\mathcal{L}*{codebook}}*{\\text{é‡åŒ–çº¦æŸ}}$$\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“˜ 9. æ—¥å¿—é¡¹ï¼ˆlogï¼‰è¾“å‡ºè¯´æ˜Ž\n",
    "\n",
    "æ¨¡åž‹åœ¨è®­ç»ƒæ—¶ä¼šè®°å½•ï¼š\n",
    "\n",
    "| åç§°            | å«ä¹‰            |\n",
    "| ------------- | ------------- |\n",
    "| `total_loss`  | æ€»æŸå¤±           |\n",
    "| `quant_loss`  | ç æœ¬æŸå¤±          |\n",
    "| `rec_loss`    | é‡å»ºæŸå¤±ï¼ˆåƒç´  + æ„ŸçŸ¥ï¼‰ |\n",
    "| `p_loss`      | LPIPSæ„ŸçŸ¥éƒ¨åˆ†     |\n",
    "| `d_weight`    | å½“å‰è‡ªé€‚åº”æƒé‡       |\n",
    "| `disc_factor` | åˆ¤åˆ«å™¨å¯ç”¨æƒé‡       |\n",
    "| `g_loss`      | ç”Ÿæˆå™¨GANæŸå¤±      |\n",
    "| `disc_loss`   | åˆ¤åˆ«å™¨æŸå¤±         |\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 10. å°ç»“ï¼šä¸Žè®ºæ–‡å¯¹åº”å…³ç³»\n",
    "\n",
    "| ä»£ç é¡¹                         | è®ºæ–‡å…¬å¼                         | ä½œç”¨        |\n",
    "| --------------------------- | ---------------------------- | --------- |\n",
    "| `nll_loss`                  | (\\mathcal{L}_{rec})          | é‡å»ºï¼ˆåƒç´ /æ„ŸçŸ¥ï¼‰ |\n",
    "| `codebook_loss`             | (\\mathcal{L}_{VQ})           | é‡åŒ–ä¸€è‡´æ€§     |\n",
    "| `g_loss`                    | (\\mathcal{L}_{GAN}(E,G,Z,D)) | ç”Ÿæˆå™¨å¯¹æŠ—é¡¹    |\n",
    "| `d_loss`                    | (\\mathcal{L}_{D})            | åˆ¤åˆ«å™¨æ›´æ–°     |\n",
    "| `calculate_adaptive_weight` | Eq.(7)                       | è‡ªé€‚åº”å¹³è¡¡ Î»   |\n",
    "| `adopt_weight`              | å»¶è¿Ÿåˆ¤åˆ«å™¨å¯ç”¨                      | è®­ç»ƒç¨³å®šæ€§æŠ€å·§   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQLPIPSWithDiscriminator(nn.Module):\n",
    "    def __init__(self, disc_start, codebook_weight=1.0, pixelloss_weight=1.0,\n",
    "                 disc_num_layers=3, disc_in_channels=3, disc_factor=1.0, disc_weight=1.0,\n",
    "                 perceptual_weight=1.0, use_actnorm=False, disc_conditional=False,\n",
    "                 disc_ndf=64, disc_loss=\"hinge\"):\n",
    "        super().__init__()\n",
    "        assert disc_loss in [\"hinge\", \"vanilla\"]\n",
    "        self.codebook_weight = codebook_weight\n",
    "        self.pixel_weight = pixelloss_weight\n",
    "        self.perceptual_loss = LPIPS().eval()\n",
    "        self.perceptual_weight = perceptual_weight\n",
    "\n",
    "        self.discriminator = NLayerDiscriminator(input_nc=disc_in_channels,\n",
    "                                                 n_layers=disc_num_layers,\n",
    "                                                 use_actnorm=use_actnorm,\n",
    "                                                 ndf=disc_ndf\n",
    "                                                 ).apply(weights_init)\n",
    "        self.discriminator_iter_start = disc_start\n",
    "        if disc_loss == \"hinge\":\n",
    "            self.disc_loss = hinge_d_loss\n",
    "        elif disc_loss == \"vanilla\":\n",
    "            self.disc_loss = vanilla_d_loss\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown GAN loss '{disc_loss}'.\")\n",
    "        print(f\"VQLPIPSWithDiscriminator running with {disc_loss} loss.\")\n",
    "        self.disc_factor = disc_factor\n",
    "        self.discriminator_weight = disc_weight\n",
    "        self.disc_conditional = disc_conditional\n",
    "\n",
    "    def calculate_adaptive_weight(self, nll_loss, g_loss, last_layer=None):\n",
    "        if last_layer is not None:\n",
    "            nll_grads = torch.autograd.grad(nll_loss, last_layer, retain_graph=True)[0]\n",
    "            g_grads = torch.autograd.grad(g_loss, last_layer, retain_graph=True)[0]\n",
    "        else:\n",
    "            nll_grads = torch.autograd.grad(nll_loss, self.last_layer[0], retain_graph=True)[0]\n",
    "            g_grads = torch.autograd.grad(g_loss, self.last_layer[0], retain_graph=True)[0]\n",
    "\n",
    "        d_weight = torch.norm(nll_grads) / (torch.norm(g_grads) + 1e-4)\n",
    "        d_weight = torch.clamp(d_weight, 0.0, 1e4).detach()\n",
    "        d_weight = d_weight * self.discriminator_weight\n",
    "        return d_weight\n",
    "\n",
    "    def forward(self, codebook_loss, inputs, reconstructions, optimizer_idx,\n",
    "                global_step, last_layer=None, cond=None, split=\"train\"):\n",
    "        rec_loss = torch.abs(inputs.contiguous() - reconstructions.contiguous())\n",
    "        if self.perceptual_weight > 0:\n",
    "            p_loss = self.perceptual_loss(inputs.contiguous(), reconstructions.contiguous())\n",
    "            rec_loss = rec_loss + self.perceptual_weight * p_loss\n",
    "        else:\n",
    "            p_loss = torch.tensor([0.0])\n",
    "\n",
    "        nll_loss = rec_loss\n",
    "        #nll_loss = torch.sum(nll_loss) / nll_loss.shape[0]\n",
    "        nll_loss = torch.mean(nll_loss)\n",
    "\n",
    "        # now the GAN part\n",
    "        if optimizer_idx == 0:\n",
    "            # generator update\n",
    "            if cond is None:\n",
    "                assert not self.disc_conditional\n",
    "                logits_fake = self.discriminator(reconstructions.contiguous())\n",
    "            else:\n",
    "                assert self.disc_conditional\n",
    "                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous(), cond), dim=1))\n",
    "            g_loss = -torch.mean(logits_fake)\n",
    "\n",
    "            try:\n",
    "                d_weight = self.calculate_adaptive_weight(nll_loss, g_loss, last_layer=last_layer)\n",
    "            except RuntimeError:\n",
    "                assert not self.training\n",
    "                d_weight = torch.tensor(0.0)\n",
    "\n",
    "            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n",
    "            loss = nll_loss + d_weight * disc_factor * g_loss + self.codebook_weight * codebook_loss.mean()\n",
    "\n",
    "            log = {\"{}/total_loss\".format(split): loss.clone().detach().mean(),\n",
    "                   \"{}/quant_loss\".format(split): codebook_loss.detach().mean(),\n",
    "                   \"{}/nll_loss\".format(split): nll_loss.detach().mean(),\n",
    "                   \"{}/rec_loss\".format(split): rec_loss.detach().mean(),\n",
    "                   \"{}/p_loss\".format(split): p_loss.detach().mean(),\n",
    "                   \"{}/d_weight\".format(split): d_weight.detach(),\n",
    "                   \"{}/disc_factor\".format(split): torch.tensor(disc_factor),\n",
    "                   \"{}/g_loss\".format(split): g_loss.detach().mean(),\n",
    "                   }\n",
    "            return loss, log\n",
    "\n",
    "        if optimizer_idx == 1:\n",
    "            # second pass for discriminator update\n",
    "            if cond is None:\n",
    "                logits_real = self.discriminator(inputs.contiguous().detach())\n",
    "                logits_fake = self.discriminator(reconstructions.contiguous().detach())\n",
    "            else:\n",
    "                logits_real = self.discriminator(torch.cat((inputs.contiguous().detach(), cond), dim=1))\n",
    "                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous().detach(), cond), dim=1))\n",
    "\n",
    "            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n",
    "            d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n",
    "\n",
    "            log = {\"{}/disc_loss\".format(split): d_loss.clone().detach().mean(),\n",
    "                   \"{}/logits_real\".format(split): logits_real.detach().mean(),\n",
    "                   \"{}/logits_fake\".format(split): logits_fake.detach().mean()\n",
    "                   }\n",
    "            return d_loss, log\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad71d264",
   "metadata": {},
   "source": [
    "# VQ-GAN论文阅读+代码解析\n",
    "\n",
    "> 第一次写：0928\n",
    "> \n",
    "> 第二次补充： 2025-10-08 19:09:54 Wednesday\n",
    "\n",
    "重要观点：\n",
    "1. **VQ-GAN中的Transformer属于通道注意力结构**:其设计融合了CNN特征提取的思想。注意力并非直接在像素层面展开，而是在卷积网络提取的多通道特征图上进行建模，从而在保持局部空间一致性的同时，引入全局依赖关系。\n",
    "\n",
    "2.  **VQ-GAN能保留丰富图像信息并实现高质量重建的关键在于其token（码本向量）设计**:这些离散token并非仅表示某个像素块的颜色，而是通过多层卷积编码器（encoder）下采样后获得的高层语义表征，因而每个token都蕴含其邻域的结构与语义上下文。这种“上下文丰富”的embedding token使得Transformer阶段能够理解全局物体形状、边界与语义关系，从而在合成时生成结构一致、内容真实的图像。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290b7f6",
   "metadata": {},
   "source": [
    "## 文章动机\n",
    "\n",
    "为了解决 Transformer **在图像生成领域的两大根本性瓶颈**：，而提出将卷积网络的高效局部建模与Transformer的强大全局建模相结合，使Transformer能在高分辨率图像生成中既高效又具有全局语义一致性。\n",
    "### **1️⃣ 瓶颈一：像素级Transformer的复杂度太高**\n",
    "\n",
    "* 直接在像素空间上对图像进行自回归建模（如 PixelRNN、Image Transformer）会导致：\n",
    "  $$\\text{复杂度} = O(H^2W^2)$$\n",
    "  也就是随分辨率平方级增长。\n",
    "* 这样在高分辨率（例如 512×512 甚至更大）时几乎无法训练或采样。\n",
    "\n",
    "\n",
    "### **2️⃣ 瓶颈二：像素缺乏“上下文语义”**\n",
    "\n",
    "* 每个像素或小patch独立编码，Transformer要自己“学习”全局结构和语义（比如物体的形状、轮廓），效率极低；\n",
    "* 缺乏归纳偏置（inductive bias），导致训练不稳定、生成质量低。\n",
    "\n",
    "\n",
    "### 💡 提出的方案\n",
    "\n",
    "> **“让Transformer不再直接看像素，而是看语义token。”**\n",
    "\n",
    "* 通过 **VQ-GAN** 的编码器（CNN结构）先将图像压缩成**上下文丰富的离散token**（即视觉词汇表中的code）。\n",
    "* 这些token不是原始像素，而是融合了局部结构与语义的高层特征。\n",
    "* 最后Transformer可以利用这些**低维、语义化的token序列**上进行自回归建模。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21cba9",
   "metadata": {},
   "source": [
    "## GroupNorm？\n",
    "\n",
    "- GroupNorm 将输入特征图的通道（Channel）划分为若干个小组（Group），在每个小组内部独立进行归一化操作（计算均值和方差，并通过缩放和平移调整分布）。\n",
    "- 好处是GroupNorm 通过按通道分组进行归一化，摆脱了对批量大小的依赖，在小批量场景下比 BatchNorm 更鲁棒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed2e410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from icecream import ic\n",
    "def Normalize(in_channels, num_groups=32):\n",
    "    return torch.nn.GroupNorm(num_groups=num_groups, num_channels=in_channels, eps=1e-6, affine=True)\n",
    "\n",
    "\n",
    "def nonlinearity(x):\n",
    "    # swish\n",
    "    return x*torch.sigmoid(x)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if self.with_conv:\n",
    "            # no asymmetric padding in torch conv, must do it ourselves\n",
    "            self.conv = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=2,\n",
    "                                        padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.with_conv:\n",
    "            pad = (0,1,0,1)\n",
    "            x = torch.nn.functional.pad(x, pad, mode=\"constant\", value=0)\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        return x\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if self.with_conv:\n",
    "            self.conv = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n",
    "        if self.with_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590af6d",
   "metadata": {},
   "source": [
    "## 通道注意力\n",
    "\n",
    "**通道注意力是什么?**\n",
    "\n",
    "通道注意力通过对各通道进行加权组合，从整体上突出重要通道、抑制次要通道；若从单个通道角度来看，其效果可等价为一次仿射变换（缩放与平移）。\n",
    "\n",
    "\n",
    "\n",
    "**不同任务下的注意力机制含义?**\n",
    "\n",
    "- NLP 任务：主要在序列维度上建模（词与词之间的关系），注意力机制用于突出文本序列中关键的 token。\n",
    "\n",
    "- 图像任务：注意力可以作用于不同维度\n",
    "    - 通道注意力：强调重要通道的信息，抑制次要通道。\n",
    "    - 空间注意力：突出不同 patch 或像素的位置重要性。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**位置编码问题**\n",
    "\n",
    "- 文本注意力：一维位置编码是必须的，用于保留序列顺序信息。\n",
    "\n",
    "- 图像空间注意力：二维位置编码通常是必须的，尤其在全局注意力或 Transformer 架构中，用于保留像素或 patch 的空间关系。\n",
    "\n",
    "- 图像通道注意力：输入通常是经过卷积提取的特征图，已经隐含空间信息，因此不需要额外的位置编码。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ab95ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mw_\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mout\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 16, 16])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch_diffusion + derived encoder decoder\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.norm = Normalize(in_channels)\n",
    "        self.q = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.k = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.v = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.proj_out = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=1,\n",
    "                                        stride=1,\n",
    "                                        padding=0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = x\n",
    "        h_ = self.norm(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "        ic(q.shape)\n",
    "\n",
    "        # compute attention\n",
    "        b,c,h,w = q.shape\n",
    "        q = q.reshape(b,c,h*w)\n",
    "        q = q.permute(0,2,1)   # b,hw,c\n",
    "        k = k.reshape(b,c,h*w) # b,c,hw\n",
    "        ic(q.shape)\n",
    "        w_ = torch.bmm(q,k)     # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]\n",
    "        ic(w_.shape)\n",
    "        w_ = w_ * (int(c)**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_, dim=2)\n",
    "\n",
    "        # attend to values\n",
    "        v = v.reshape(b,c,h*w)\n",
    "        w_ = w_.permute(0,2,1)   # b,hw,hw (first hw of k, second of q)\n",
    "        h_ = torch.bmm(v,w_)     # b, c,hw (hw of q) h_[b,c,j] = sum_i v[b,c,i] w_[b,i,j]\n",
    "        h_ = h_.reshape(b,c,h,w)\n",
    "\n",
    "        h_ = self.proj_out(h_)\n",
    "\n",
    "        return x+h_\n",
    "\n",
    "\n",
    "\n",
    "def make_attn(in_channels, attn_type=\"vanilla\"):\n",
    "    assert attn_type in [\"vanilla\", \"linear\", \"none\"], f'attn_type {attn_type} unknown'\n",
    "    print(f\"making attention of type '{attn_type}' with {in_channels} in_channels\")\n",
    "    if attn_type == \"vanilla\":\n",
    "        return AttnBlock(in_channels)\n",
    "    elif attn_type == \"none\":\n",
    "        return nn.Identity(in_channels)\n",
    "    else:\n",
    "        return LinAttnBlock(in_channels)\n",
    "\n",
    "\n",
    "img=torch.rand(2,512,16,16)\n",
    "attn=AttnBlock(img.shape[1])\n",
    "\n",
    "out=attn(img)\n",
    "ic(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a35f6",
   "metadata": {},
   "source": [
    "## 残差网络块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7140a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False,\n",
    "                 dropout, temb_channels=512):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        out_channels = in_channels if out_channels is None else out_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_conv_shortcut = conv_shortcut\n",
    "\n",
    "        self.norm1 = Normalize(in_channels)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1,\n",
    "                                     padding=1)\n",
    "        if temb_channels > 0:\n",
    "            self.temb_proj = torch.nn.Linear(temb_channels,\n",
    "                                             out_channels)\n",
    "        self.norm2 = Normalize(out_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1,\n",
    "                                     padding=1)\n",
    "        if self.in_channels != self.out_channels:\n",
    "            if self.use_conv_shortcut:\n",
    "                self.conv_shortcut = torch.nn.Conv2d(in_channels,\n",
    "                                                     out_channels,\n",
    "                                                     kernel_size=3,\n",
    "                                                     stride=1,\n",
    "                                                     padding=1)\n",
    "            else:\n",
    "                self.nin_shortcut = torch.nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=1,\n",
    "                                                    padding=0)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = x\n",
    "        h = self.norm1(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        if temb is not None:\n",
    "            h = h + self.temb_proj(nonlinearity(temb))[:,:,None,None]\n",
    "\n",
    "        h = self.norm2(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if self.in_channels != self.out_channels:\n",
    "            if self.use_conv_shortcut:\n",
    "                x = self.conv_shortcut(x)\n",
    "            else:\n",
    "                x = self.nin_shortcut(x)\n",
    "\n",
    "        return x+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "160753d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_diffusion + derived encoder decoder\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.norm = Normalize(in_channels)\n",
    "        self.q = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.k = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.v = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.proj_out = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=1,\n",
    "                                        stride=1,\n",
    "                                        padding=0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = x\n",
    "        h_ = self.norm(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "\n",
    "        # compute attention\n",
    "        b,c,h,w = q.shape\n",
    "        q = q.reshape(b,c,h*w)\n",
    "        q = q.permute(0,2,1)   # b,hw,c\n",
    "        k = k.reshape(b,c,h*w) # b,c,hw\n",
    "        w_ = torch.bmm(q,k)     # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]\n",
    "        w_ = w_ * (int(c)**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_, dim=2)\n",
    "\n",
    "        # attend to values\n",
    "        v = v.reshape(b,c,h*w)\n",
    "        w_ = w_.permute(0,2,1)   # b,hw,hw (first hw of k, second of q)\n",
    "        h_ = torch.bmm(v,w_)     # b, c,hw (hw of q) h_[b,c,j] = sum_i v[b,c,i] w_[b,i,j]\n",
    "        h_ = h_.reshape(b,c,h,w)\n",
    "\n",
    "        h_ = self.proj_out(h_)\n",
    "\n",
    "        return x+h_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98356c8d",
   "metadata": {},
   "source": [
    "## Encoder网络结构构成\n",
    "\n",
    "\n",
    "1. 将输入图片转成等大小多通道的初始特征图（通道数:ch=128）\n",
    "2. 下采样阶段，\n",
    "    - 包含3个子阶段，每个子阶段的通道数为ch_mult[i]*ch，每次分辨率下降1倍\n",
    "    - 即chu_mult: [1,2,4]，则通道数变化：ch=128->128->256->512\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acf8bc19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mattn_type\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mvanilla\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi_level\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m0\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247min_ch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mnum_res_blocks\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi_level\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247min_ch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mnum_res_blocks\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mi_level\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247min_ch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mch_mult\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m4\u001b[39m\u001b[38;5;245m]\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mnum_res_blocks\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mdown\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdownsample\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDownsample\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnin_shortcut\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m128\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdownsample\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDownsample\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnin_shortcut\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mx\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                       \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                     \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                   \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModuleList\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                 \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m               \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mblock_in\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mmid\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mModule\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock_1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mattn_1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mAttnBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mk\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mv\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mproj_out\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mblock_2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mResnetBlock\u001b[39m\u001b[38;5;245m(\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mnorm2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mGroupNorm\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m32\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247meps\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m1e-06\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247maffine\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mdropout\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mDropout\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mp\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minplace\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                  \u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mconv2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mself\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mconv_out\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mConv2d\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mkernel_size\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mstride\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mpadding\u001b[39m\u001b[38;5;245m=\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mh\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m16\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mq\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m512\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mw_\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m256\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *, ch=1, out_ch=3, ch_mult=(1,2,4,8), num_res_blocks=2,\n",
    "                 attn_resolutions=1, dropout=0.0, resamp_with_conv=True, in_channels=2,\n",
    "                 resolution=1, z_channels=2, double_z=True, use_linear_attn=False, attn_type=\"vanilla\",\n",
    "                 **ignore_kwargs):\n",
    "        super().__init__()\n",
    "        if use_linear_attn: attn_type = \"linear\"\n",
    "        ic(attn_type)\n",
    "        self.ch = ch\n",
    "        self.temb_ch = 0\n",
    "        self.num_resolutions = len(ch_mult)\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.resolution = resolution\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # downsampling\n",
    "        self.conv_in = torch.nn.Conv2d(in_channels,\n",
    "                                       self.ch,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1)\n",
    "\n",
    "        curr_res = resolution\n",
    "        in_ch_mult = (1,)+tuple(ch_mult)\n",
    "        self.in_ch_mult = in_ch_mult\n",
    "        self.down = nn.ModuleList()\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_in = ch*in_ch_mult[i_level]\n",
    "            block_out = ch*ch_mult[i_level]\n",
    "            ic(i_level)\n",
    "            ic(block_in)\n",
    "            ic(block_out)\n",
    "            ic(in_ch_mult,ch_mult)\n",
    "            ic(self.num_res_blocks)\n",
    "            \n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                block.append(ResnetBlock(in_channels=block_in,\n",
    "                                         out_channels=block_out,\n",
    "                                         temb_channels=self.temb_ch,\n",
    "                                         dropout=dropout))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(make_attn(block_in, attn_type=attn_type))\n",
    "            down = nn.Module()\n",
    "            down.block = block\n",
    "            down.attn = attn\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                down.downsample = Downsample(block_in, resamp_with_conv)\n",
    "                curr_res = curr_res // 2\n",
    "            self.down.append(down)\n",
    "        ic(self.down)\n",
    "\n",
    "        # middle\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        ic(block_in)\n",
    "        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n",
    "        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        \n",
    "        ic(self.mid)\n",
    "\n",
    "        # end\n",
    "        self.norm_out = Normalize(block_in)\n",
    "        self.conv_out = torch.nn.Conv2d(block_in,\n",
    "                                        2*z_channels if double_z else z_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "        ic(self.conv_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # timestep embedding\n",
    "        temb = None\n",
    "\n",
    "        # downsampling\n",
    "        hs = [self.conv_in(x)]\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                h = self.down[i_level].block[i_block](hs[-1], temb)\n",
    "                if len(self.down[i_level].attn) > 0:\n",
    "                    h = self.down[i_level].attn[i_block](h)\n",
    "                hs.append(h)\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                hs.append(self.down[i_level].downsample(hs[-1]))\n",
    "\n",
    "        # middle\n",
    "        h = hs[-1]\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        ic(h.shape)\n",
    "        h = self.mid.attn_1(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "\n",
    "        # end\n",
    "        h = self.norm_out(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv_out(h)\n",
    "        return h\n",
    "\n",
    "ddconfig = {\n",
    "    \"double_z\": False,\n",
    "    \"z_channels\": 3,\n",
    "    \"resolution\": 64,\n",
    "    \"in_channels\": 1,\n",
    "    \"out_ch\": 1,\n",
    "    \"ch\": 128,\n",
    "    \"ch_mult\": [1, 2, 4],\n",
    "    \"num_res_blocks\": 3,\n",
    "    \"attn_resolutions\": [],\n",
    "    \"dropout\": 0.0\n",
    "}\n",
    "\n",
    "encoder=Encoder(**ddconfig)\n",
    "\n",
    "random_input = torch.randn(2, ddconfig[\"in_channels\"], ddconfig[\"resolution\"], ddconfig[\"resolution\"])\n",
    "\n",
    "# 前向传播\n",
    "output = encoder(random_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6a08b",
   "metadata": {},
   "source": [
    "## Decoder网络构成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ace6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 3, 16, 16) = 768 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n",
    "                 attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n",
    "                 resolution, z_channels, give_pre_end=False, tanh_out=False, use_linear_attn=False,\n",
    "                 attn_type=\"vanilla\", **ignorekwargs):\n",
    "        super().__init__()\n",
    "        if use_linear_attn: attn_type = \"linear\"\n",
    "        self.ch = ch\n",
    "        self.temb_ch = 0\n",
    "        self.num_resolutions = len(ch_mult)\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.resolution = resolution\n",
    "        self.in_channels = in_channels\n",
    "        self.give_pre_end = give_pre_end\n",
    "        self.tanh_out = tanh_out\n",
    "\n",
    "        # compute in_ch_mult, block_in and curr_res at lowest res\n",
    "        in_ch_mult = (1,)+tuple(ch_mult)\n",
    "        block_in = ch*ch_mult[self.num_resolutions-1]\n",
    "        curr_res = resolution // 2**(self.num_resolutions-1)\n",
    "        self.z_shape = (1,z_channels,curr_res,curr_res)\n",
    "        print(\"Working with z of shape {} = {} dimensions.\".format(\n",
    "            self.z_shape, np.prod(self.z_shape)))\n",
    "\n",
    "        # z to block_in\n",
    "        self.conv_in = torch.nn.Conv2d(z_channels,\n",
    "                                       block_in,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1)\n",
    "\n",
    "        # middle\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n",
    "        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "\n",
    "        # upsampling\n",
    "        self.up = nn.ModuleList()\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_out = ch*ch_mult[i_level]\n",
    "            for i_block in range(self.num_res_blocks+1):\n",
    "                block.append(ResnetBlock(in_channels=block_in,\n",
    "                                         out_channels=block_out,\n",
    "                                         temb_channels=self.temb_ch,\n",
    "                                         dropout=dropout))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(make_attn(block_in, attn_type=attn_type))\n",
    "            up = nn.Module()\n",
    "            up.block = block\n",
    "            up.attn = attn\n",
    "            if i_level != 0:\n",
    "                up.upsample = Upsample(block_in, resamp_with_conv)\n",
    "                curr_res = curr_res * 2\n",
    "            self.up.insert(0, up) # prepend to get consistent order\n",
    "\n",
    "        # end\n",
    "        self.norm_out = Normalize(block_in)\n",
    "        self.conv_out = torch.nn.Conv2d(block_in,\n",
    "                                        out_ch,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        #assert z.shape[1:] == self.z_shape[1:]\n",
    "        self.last_z_shape = z.shape\n",
    "\n",
    "        # timestep embedding\n",
    "        temb = None\n",
    "\n",
    "        # z to block_in\n",
    "        h = self.conv_in(z)\n",
    "\n",
    "        # middle\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        h = self.mid.attn_1(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "\n",
    "        # upsampling\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            for i_block in range(self.num_res_blocks+1):\n",
    "                h = self.up[i_level].block[i_block](h, temb)\n",
    "                if len(self.up[i_level].attn) > 0:\n",
    "                    h = self.up[i_level].attn[i_block](h)\n",
    "            if i_level != 0:\n",
    "                h = self.up[i_level].upsample(h)\n",
    "\n",
    "        # end\n",
    "        if self.give_pre_end:\n",
    "            return h\n",
    "\n",
    "        h = self.norm_out(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv_out(h)\n",
    "        if self.tanh_out:\n",
    "            h = torch.tanh(h)\n",
    "        return h\n",
    "\n",
    "decoder=Decoder(**ddconfig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bc591",
   "metadata": {},
   "source": [
    "## 向量量化器以及量化损失 $\\mathcal{L}_{codebook}$\n",
    "\n",
    "来自 `VectorQuantizer2.forward()`：\n",
    "\n",
    "```python\n",
    "if not self.legacy:\n",
    "    loss = self.beta * torch.mean((z_q.detach()-z)**2) + \\\n",
    "           torch.mean((z_q - z.detach()) ** 2)\n",
    "else:\n",
    "    loss = torch.mean((z_q.detach()-z)**2) + \\\n",
    "           self.beta * torch.mean((z_q - z.detach()) ** 2)\n",
    "```\n",
    "\n",
    "### VQ-VAE 的核心：\n",
    "将 encoder 输出 ($z_e(x)$) 替换为最邻近的 codebook 向量 ($e_k$)。\n",
    "\n",
    "\n",
    "$$\\mathcal{L}_{codebook} =\n",
    "| \\text{sg}[z_e(x)] - e_k |_2^2 +\n",
    "\\beta | z_e(x) - \\text{sg}[e_k] |_2^2$$\n",
    "\n",
    "其中 `sg[·]` 表示 **stop-gradient**，防止梯度流到该项。\n",
    "第一项更新 codebook embedding；\n",
    "第二项更新 encoder，让其靠近最近的 embedding。\n",
    "\n",
    "### 🧩 Trick: Straight-Through Estimator (STE)\n",
    "\n",
    "```python\n",
    "z_q = z + (z_q - z).detach()\n",
    "```\n",
    "\n",
    "这行是 **直通梯度估计**：\n",
    "\n",
    "* 前向：输出 (z_q)\n",
    "* 反向：梯度直接传回 (z)，绕过离散量化操作。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2efe29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VectorQuantizer2(nn.Module):\n",
    "    \"\"\"\n",
    "    Improved version over VectorQuantizer, can be used as a drop-in replacement. Mostly\n",
    "    avoids costly matrix multiplications and allows for post-hoc remapping of indices.\n",
    "    \"\"\"\n",
    "    # NOTE: due to a bug the beta term was applied to the wrong term. for\n",
    "    # backwards compatibility we use the buggy version by default, but you can\n",
    "    # specify legacy=False to fix it.\n",
    "    def __init__(self, n_e, e_dim, beta, remap=None, unknown_index=\"random\",\n",
    "                 sane_index_shape=False, legacy=True):\n",
    "        super().__init__()\n",
    "        self.n_e = n_e\n",
    "        self.e_dim = e_dim\n",
    "        self.beta = beta\n",
    "        self.legacy = legacy\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_e, self.e_dim)\n",
    "        self.embedding.weight.data.uniform_(-1.0 / self.n_e, 1.0 / self.n_e)\n",
    "\n",
    "        self.remap = remap\n",
    "        if self.remap is not None:\n",
    "            self.register_buffer(\"used\", torch.tensor(np.load(self.remap)))\n",
    "            self.re_embed = self.used.shape[0]\n",
    "            self.unknown_index = unknown_index # \"random\" or \"extra\" or integer\n",
    "            if self.unknown_index == \"extra\":\n",
    "                self.unknown_index = self.re_embed\n",
    "                self.re_embed = self.re_embed+1\n",
    "            print(f\"Remapping {self.n_e} indices to {self.re_embed} indices. \"\n",
    "                  f\"Using {self.unknown_index} for unknown indices.\")\n",
    "        else:\n",
    "            self.re_embed = n_e\n",
    "\n",
    "        self.sane_index_shape = sane_index_shape\n",
    "\n",
    "    def remap_to_used(self, inds):\n",
    "        ishape = inds.shape\n",
    "        assert len(ishape)>1\n",
    "        inds = inds.reshape(ishape[0],-1)\n",
    "        used = self.used.to(inds)\n",
    "        match = (inds[:,:,None]==used[None,None,...]).long()\n",
    "        new = match.argmax(-1)\n",
    "        unknown = match.sum(2)<1\n",
    "        if self.unknown_index == \"random\":\n",
    "            new[unknown]=torch.randint(0,self.re_embed,size=new[unknown].shape).to(device=new.device)\n",
    "        else:\n",
    "            new[unknown] = self.unknown_index\n",
    "        return new.reshape(ishape)\n",
    "\n",
    "    def unmap_to_all(self, inds):\n",
    "        ishape = inds.shape\n",
    "        assert len(ishape)>1\n",
    "        inds = inds.reshape(ishape[0],-1)\n",
    "        used = self.used.to(inds)\n",
    "        if self.re_embed > self.used.shape[0]: # extra token\n",
    "            inds[inds>=self.used.shape[0]] = 0 # simply set to zero\n",
    "        back=torch.gather(used[None,:][inds.shape[0]*[0],:], 1, inds)\n",
    "        return back.reshape(ishape)\n",
    "\n",
    "    def forward(self, z, temp=None, rescale_logits=False, return_logits=False):\n",
    "        assert temp is None or temp==1.0, \"Only for interface compatible with Gumbel\"\n",
    "        assert rescale_logits==False, \"Only for interface compatible with Gumbel\"\n",
    "        assert return_logits==False, \"Only for interface compatible with Gumbel\"\n",
    "        # reshape z -> (batch, height, width, channel) and flatten\n",
    "        z = rearrange(z, 'b c h w -> b h w c').contiguous()\n",
    "        z_flattened = z.view(-1, self.e_dim)\n",
    "        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n",
    "\n",
    "        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n",
    "            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n",
    "            torch.einsum('bd,dn->bn', z_flattened, rearrange(self.embedding.weight, 'n d -> d n'))\n",
    "\n",
    "        min_encoding_indices = torch.argmin(d, dim=1)\n",
    "        z_q = self.embedding(min_encoding_indices).view(z.shape)\n",
    "        perplexity = None\n",
    "        min_encodings = None\n",
    "\n",
    "        # compute loss for embedding\n",
    "        if not self.legacy:\n",
    "            loss = self.beta * torch.mean((z_q.detach()-z)**2) + \\\n",
    "                   torch.mean((z_q - z.detach()) ** 2)\n",
    "        else:\n",
    "            loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n",
    "                   torch.mean((z_q - z.detach()) ** 2)\n",
    "\n",
    "        # preserve gradients\n",
    "        z_q = z + (z_q - z).detach()\n",
    "\n",
    "        # reshape back to match original input shape\n",
    "        z_q = rearrange(z_q, 'b h w c -> b c h w').contiguous()\n",
    "\n",
    "        if self.remap is not None:\n",
    "            min_encoding_indices = min_encoding_indices.reshape(z.shape[0],-1) # add batch axis\n",
    "            min_encoding_indices = self.remap_to_used(min_encoding_indices)\n",
    "            min_encoding_indices = min_encoding_indices.reshape(-1,1) # flatten\n",
    "\n",
    "        if self.sane_index_shape:\n",
    "            min_encoding_indices = min_encoding_indices.reshape(\n",
    "                z_q.shape[0], z_q.shape[2], z_q.shape[3])\n",
    "\n",
    "        return z_q, loss, (perplexity, min_encodings, min_encoding_indices)\n",
    "\n",
    "    def get_codebook_entry(self, indices, shape):\n",
    "        # shape specifying (batch, height, width, channel)\n",
    "        if self.remap is not None:\n",
    "            indices = indices.reshape(shape[0],-1) # add batch axis\n",
    "            indices = self.unmap_to_all(indices)\n",
    "            indices = indices.reshape(-1) # flatten again\n",
    "\n",
    "        # get quantized latent vectors\n",
    "        z_q = self.embedding(indices)\n",
    "\n",
    "        if shape is not None:\n",
    "            z_q = z_q.view(shape)\n",
    "            # reshape back to match original input shape\n",
    "            z_q = z_q.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        return z_q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28669f2",
   "metadata": {},
   "source": [
    "\n",
    "## VQ-GAN的损失函数 (代码实现为VQLPIPSWithDiscriminator类)\n",
    "这个类实现的正是 VQ-GAN 论文中的损失结构：\n",
    "$$\\mathcal{L}*{total} = \\mathcal{L}*{rec/perceptual} + \\lambda \\mathcal{L}*{GAN} + \\beta \\mathcal{L}*{codebook}$$\n",
    "并通过自适应权重 λ 平衡重建与对抗两部分的梯度强度。\n",
    "\n",
    "\n",
    "其中：\n",
    "  * **$\\mathcal{L}_{rec}$**：重建损失（像素 + 感知损失）\n",
    "  * **$\\mathcal{L}_{GAN}$**：对抗损失（生成器部分）\n",
    "  * **$\\mathcal{L}_{codebook}$**：量化损失（codebook embedding 更新）\n",
    "  * **$\\lambda$**：自适应平衡权重（梯度范数比）\n",
    "  * **$\\beta$**：VQ 中控制 embedding 更新的比例因子\n",
    "\n",
    "---\n",
    "\n",
    "### 🧱 1. 模型结构组成\n",
    "\n",
    "| 模块              | 含义                                  |\n",
    "| --------------- | ----------------------------------- |\n",
    "| `E` / `G` / `Z` | 分别是 encoder、decoder、codebook        |\n",
    "| `D`             | 判别器（PatchGAN 类型）                    |\n",
    "| `LPIPS`         | 感知损失（perceptual loss），使用预训练网络计算特征差异 |\n",
    "| `codebook_loss` | 码本量化损失（commitment + embedding）      |\n",
    "| `disc_loss`     | 对抗损失，可选 \"hinge\" 或 \"vanilla\"         |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ 2. 总体前向逻辑\n",
    "\n",
    "在 `forward()` 中根据 `optimizer_idx` 分为两步：\n",
    "\n",
    "1. `optimizer_idx == 0`：更新生成器（E, G, Z）\n",
    "2. `optimizer_idx == 1`：更新判别器 D\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 3. 重建 + 感知损失（Reconstruction + Perceptual）\n",
    "\n",
    "```python\n",
    "rec_loss = torch.abs(inputs - reconstructions)\n",
    "p_loss = self.perceptual_loss(inputs, reconstructions)\n",
    "rec_loss = rec_loss + self.perceptual_weight * p_loss\n",
    "nll_loss = torch.mean(rec_loss)\n",
    "```\n",
    "\n",
    "对应公式：\n",
    "\n",
    "$$\\mathcal{L}_{rec/perceptual} =\n",
    "\\mathbb{E}[|x - \\hat{x}|_1] +\n",
    "\\lambda_p |\\phi(x) - \\phi(\\hat{x})|_2^2$$\n",
    "\n",
    "* `L1` 替代了像素级 L2，更鲁棒；\n",
    "* `LPIPS` 提供感知层面的特征距离；\n",
    "* `perceptual_weight` 控制感知损失的权重；\n",
    "* `nll_loss` 相当于 Eq.(6) 中的 ($\\mathcal{L}_{rec}$)。\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 4. Codebook 量化损失\n",
    "\n",
    "在 VQ-VAE/VQ-GAN 中：\n",
    "\n",
    "$$\\mathcal{L}_{codebook} = |\\text{sg}[E(x)] - z_q|^2 + |E(x) - \\text{sg}[z_q]|^2$$\n",
    "\n",
    "这里在总损失中体现为：\n",
    "\n",
    "```python\n",
    "loss += self.codebook_weight * codebook_loss.mean()\n",
    "```\n",
    "\n",
    "表示 “保持编码器与码本一致性” 的约束项。\n",
    "\n",
    "---\n",
    "\n",
    "### 🎭 5. 对抗损失（Adversarial Loss）\n",
    "\n",
    "#### ➤ Generator（更新生成器时）\n",
    "  ```python\n",
    "  logits_fake = self.discriminator(reconstructions)\n",
    "  g_loss = -torch.mean(logits_fake)\n",
    "  ```\n",
    "  * 对应 **hinge-GAN 生成器损失**：\n",
    "    $$\\mathcal{L}_G = -\\mathbb{E}[D(\\hat{x})]$$\n",
    "  * 即希望生成图像的判别得分高（骗过 D）。\n",
    "\n",
    "#### ➤ Discriminator（更新判别器时）\n",
    "\n",
    "  ```python\n",
    "  logits_real = self.discriminator(inputs.detach())\n",
    "  logits_fake = self.discriminator(reconstructions.detach())\n",
    "  d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n",
    "  ```\n",
    "\n",
    "* 对应 **hinge-GAN 判别器损失**：\n",
    "  $$\\mathcal{L}_D =\n",
    "  \\mathbb{E}[\\max(0, 1 - D(x))] + \\mathbb{E}[\\max(0, 1 + D(\\hat{x}))]$$\n",
    "\n",
    "* 若为 vanilla-GAN，则换为：\n",
    "  $$\\mathcal{L}_D = -[\\log D(x) + \\log(1 - D(\\hat{x}))]$$\n",
    "\n",
    "---\n",
    "\n",
    "### ⚖️ 6. 自适应权重 λ（Adaptive Weight）\n",
    "\n",
    "```python\n",
    "d_weight = self.calculate_adaptive_weight(nll_loss, g_loss, last_layer)\n",
    "```\n",
    "\n",
    "公式对应 Eq.(7)：\n",
    "\n",
    "$$\\lambda = \\frac{|\\nabla_{G_L}[\\mathcal{L}*{rec}]|}\n",
    "{|\\nabla*{G_L}[\\mathcal{L}_{GAN}]| + \\delta}$$\n",
    "\n",
    "实现技巧：\n",
    "\n",
    "* 通过 `torch.autograd.grad` 对最后一层梯度取范数；\n",
    "* 避免除零，用 `+ 1e-4`；\n",
    "* `torch.clamp()` 限制范围；\n",
    "* 最后乘上 `self.discriminator_weight`（整体缩放因子）。\n",
    "\n",
    "**意义：**\n",
    "\n",
    "* 若 GAN 训练太强（梯度大）→ 减小 λ；\n",
    "* 若重建信号强 → 增大 λ；\n",
    "* 保证训练稳定、视觉质量与结构保真兼顾。\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 7. 判别器延迟启用技巧\n",
    "\n",
    "```python\n",
    "disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n",
    "```\n",
    "\n",
    "实现细节：\n",
    "\n",
    "* 训练初期不启用判别器（防止 GAN 不稳定）；\n",
    "* 当 `global_step > disc_start` 后再激活；\n",
    "* 相当于论文中的 “warm-up” 策略。\n",
    "\n",
    "---\n",
    "\n",
    "### 🧾 8. 总损失表达式（Generator阶段）\n",
    "\n",
    "$$\\mathcal{L}*{total} =\n",
    "\\underbrace{\\mathcal{L}*{rec/perceptual}}*{\\text{重建+感知}}+\n",
    "\\underbrace{d*{weight} \\cdot disc_{factor} \\cdot \\mathcal{L}*{GAN}}*{\\text{对抗项}}\n",
    "+\\underbrace{\\beta \\cdot \\mathcal{L}*{codebook}}*{\\text{量化约束}}$$\n",
    "\n",
    "---\n",
    "\n",
    "### 📘 9. 日志项（log）输出说明\n",
    "\n",
    "模型在训练时会记录：\n",
    "\n",
    "| 名称            | 含义            |\n",
    "| ------------- | ------------- |\n",
    "| `total_loss`  | 总损失           |\n",
    "| `quant_loss`  | 码本损失          |\n",
    "| `rec_loss`    | 重建损失（像素 + 感知） |\n",
    "| `p_loss`      | LPIPS感知部分     |\n",
    "| `d_weight`    | 当前自适应权重       |\n",
    "| `disc_factor` | 判别器启用权重       |\n",
    "| `g_loss`      | 生成器GAN损失      |\n",
    "| `disc_loss`   | 判别器损失         |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 10. 小结：与论文对应关系\n",
    "\n",
    "| 代码项                         | 论文公式                         | 作用        |\n",
    "| --------------------------- | ---------------------------- | --------- |\n",
    "| `nll_loss`                  | (\\mathcal{L}_{rec})          | 重建（像素/感知） |\n",
    "| `codebook_loss`             | (\\mathcal{L}_{VQ})           | 量化一致性     |\n",
    "| `g_loss`                    | (\\mathcal{L}_{GAN}(E,G,Z,D)) | 生成器对抗项    |\n",
    "| `d_loss`                    | (\\mathcal{L}_{D})            | 判别器更新     |\n",
    "| `calculate_adaptive_weight` | Eq.(7)                       | 自适应平衡 λ   |\n",
    "| `adopt_weight`              | 延迟判别器启用                      | 训练稳定性技巧   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQLPIPSWithDiscriminator(nn.Module):\n",
    "    def __init__(self, disc_start, codebook_weight=1.0, pixelloss_weight=1.0,\n",
    "                 disc_num_layers=3, disc_in_channels=3, disc_factor=1.0, disc_weight=1.0,\n",
    "                 perceptual_weight=1.0, use_actnorm=False, disc_conditional=False,\n",
    "                 disc_ndf=64, disc_loss=\"hinge\"):\n",
    "        super().__init__()\n",
    "        assert disc_loss in [\"hinge\", \"vanilla\"]\n",
    "        self.codebook_weight = codebook_weight\n",
    "        self.pixel_weight = pixelloss_weight\n",
    "        self.perceptual_loss = LPIPS().eval()\n",
    "        self.perceptual_weight = perceptual_weight\n",
    "\n",
    "        self.discriminator = NLayerDiscriminator(input_nc=disc_in_channels,\n",
    "                                                 n_layers=disc_num_layers,\n",
    "                                                 use_actnorm=use_actnorm,\n",
    "                                                 ndf=disc_ndf\n",
    "                                                 ).apply(weights_init)\n",
    "        self.discriminator_iter_start = disc_start\n",
    "        if disc_loss == \"hinge\":\n",
    "            self.disc_loss = hinge_d_loss\n",
    "        elif disc_loss == \"vanilla\":\n",
    "            self.disc_loss = vanilla_d_loss\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown GAN loss '{disc_loss}'.\")\n",
    "        print(f\"VQLPIPSWithDiscriminator running with {disc_loss} loss.\")\n",
    "        self.disc_factor = disc_factor\n",
    "        self.discriminator_weight = disc_weight\n",
    "        self.disc_conditional = disc_conditional\n",
    "\n",
    "    def calculate_adaptive_weight(self, nll_loss, g_loss, last_layer=None):\n",
    "        if last_layer is not None:\n",
    "            nll_grads = torch.autograd.grad(nll_loss, last_layer, retain_graph=True)[0]\n",
    "            g_grads = torch.autograd.grad(g_loss, last_layer, retain_graph=True)[0]\n",
    "        else:\n",
    "            nll_grads = torch.autograd.grad(nll_loss, self.last_layer[0], retain_graph=True)[0]\n",
    "            g_grads = torch.autograd.grad(g_loss, self.last_layer[0], retain_graph=True)[0]\n",
    "\n",
    "        d_weight = torch.norm(nll_grads) / (torch.norm(g_grads) + 1e-4)\n",
    "        d_weight = torch.clamp(d_weight, 0.0, 1e4).detach()\n",
    "        d_weight = d_weight * self.discriminator_weight\n",
    "        return d_weight\n",
    "\n",
    "    def forward(self, codebook_loss, inputs, reconstructions, optimizer_idx,\n",
    "                global_step, last_layer=None, cond=None, split=\"train\"):\n",
    "        rec_loss = torch.abs(inputs.contiguous() - reconstructions.contiguous())\n",
    "        if self.perceptual_weight > 0:\n",
    "            p_loss = self.perceptual_loss(inputs.contiguous(), reconstructions.contiguous())\n",
    "            rec_loss = rec_loss + self.perceptual_weight * p_loss\n",
    "        else:\n",
    "            p_loss = torch.tensor([0.0])\n",
    "\n",
    "        nll_loss = rec_loss\n",
    "        #nll_loss = torch.sum(nll_loss) / nll_loss.shape[0]\n",
    "        nll_loss = torch.mean(nll_loss)\n",
    "\n",
    "        # now the GAN part\n",
    "        if optimizer_idx == 0:\n",
    "            # generator update\n",
    "            if cond is None:\n",
    "                assert not self.disc_conditional\n",
    "                logits_fake = self.discriminator(reconstructions.contiguous())\n",
    "            else:\n",
    "                assert self.disc_conditional\n",
    "                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous(), cond), dim=1))\n",
    "            g_loss = -torch.mean(logits_fake)\n",
    "\n",
    "            try:\n",
    "                d_weight = self.calculate_adaptive_weight(nll_loss, g_loss, last_layer=last_layer)\n",
    "            except RuntimeError:\n",
    "                assert not self.training\n",
    "                d_weight = torch.tensor(0.0)\n",
    "\n",
    "            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n",
    "            loss = nll_loss + d_weight * disc_factor * g_loss + self.codebook_weight * codebook_loss.mean()\n",
    "\n",
    "            log = {\"{}/total_loss\".format(split): loss.clone().detach().mean(),\n",
    "                   \"{}/quant_loss\".format(split): codebook_loss.detach().mean(),\n",
    "                   \"{}/nll_loss\".format(split): nll_loss.detach().mean(),\n",
    "                   \"{}/rec_loss\".format(split): rec_loss.detach().mean(),\n",
    "                   \"{}/p_loss\".format(split): p_loss.detach().mean(),\n",
    "                   \"{}/d_weight\".format(split): d_weight.detach(),\n",
    "                   \"{}/disc_factor\".format(split): torch.tensor(disc_factor),\n",
    "                   \"{}/g_loss\".format(split): g_loss.detach().mean(),\n",
    "                   }\n",
    "            return loss, log\n",
    "\n",
    "        if optimizer_idx == 1:\n",
    "            # second pass for discriminator update\n",
    "            if cond is None:\n",
    "                logits_real = self.discriminator(inputs.contiguous().detach())\n",
    "                logits_fake = self.discriminator(reconstructions.contiguous().detach())\n",
    "            else:\n",
    "                logits_real = self.discriminator(torch.cat((inputs.contiguous().detach(), cond), dim=1))\n",
    "                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous().detach(), cond), dim=1))\n",
    "\n",
    "            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n",
    "            d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n",
    "\n",
    "            log = {\"{}/disc_loss\".format(split): d_loss.clone().detach().mean(),\n",
    "                   \"{}/logits_real\".format(split): logits_real.detach().mean(),\n",
    "                   \"{}/logits_fake\".format(split): logits_fake.detach().mean()\n",
    "                   }\n",
    "            return d_loss, log\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

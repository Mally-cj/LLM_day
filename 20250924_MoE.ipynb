{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6a45eb",
   "metadata": {},
   "source": [
    "## MoE的过程\n",
    "\n",
    "1. 用$ x $表示为包含$ T $个token的输入（$ T=\\text{batchsize}*\\text{seq\\_len} $），$ x \\in \\mathbb{R}^{T \\times d} $，$ W $表示门控权重矩阵，$ b $表示门控偏置向量，获得logits $ z \\sim \\mathbb{R}^{T \\times N} $（$ N $是专家的个数）。\n",
    "$$\n",
    "z(x) = xW + b\n",
    "$$\n",
    "2. 由logit获得路由概率$ s_{i,j}(x) $，表示第$ i $个token选择第$ j $个专家的路由概率（亲和度得分）。\n",
    "$$\n",
    "s_{i,j}(x) = \\text{softmax}(z_{i,j}(x)) = \\frac{\\exp(z_{i,j}(x))}{\\sum_{k=1}^{N} \\exp(z_{i,k}(x))}\n",
    "$$\n",
    "3. Top - $ k $选择，选出第$ i $个token的前$ K $高概率的专家：\n",
    "$$\n",
    "g_{i,j}(x) =\n",
    "\\begin{cases}\n",
    "s_{i,j}(x) & \\text{if } s_{i,j}(x) \\in \\text{TopK}(\\{s_{i,j}(x)\\}_{j = 1}^{N}, K) \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "4. 对选出的$ K $个专家重新归一化：\n",
    "$$\n",
    "v_{i,j}(x) = \\frac{g_{i,j}(x)}{\\sum_{k = 1}^{N} g_{i,k}(x)}\n",
    "$$\n",
    "5. 对于第$ i $个token的MoE输出为：\n",
    "$$\n",
    "\\text{MoE}(x_i) = \\sum_{j = 1}^{N} v_{i,j}(x) \\cdot \\text{Expert}(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030eb5a1",
   "metadata": {},
   "source": [
    "## MoE代码实现\n",
    "\n",
    "> 参考实现路径: `transformers/src/transformers/models/qwen3_moe/modular_qwen3_moe.py#L67`\n",
    "\n",
    "\n",
    "\n",
    "具体的代码实现分为两个阶段：\n",
    "1. **路由阶段**：\n",
    "- 对每个token，计算所有专家的权重（router_logits）\n",
    "- 选出top_k个权重最大的专家，同时记录哪些专家被至少一个token选中（expert_hit）\n",
    "\n",
    "2. **专家计算阶段**：\n",
    "- 对每个被选中的专家（expert_hit）：\n",
    "a. 收集所有选择该专家的token\n",
    "b. 将这些token的输入拼接起来（或保持独立）\n",
    "c. 通过该专家网络计算输出\n",
    "d. 用路由权重对输出进行加权\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59ec765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| expert_mask.shape: torch.Size([4, 2, 10])\n",
      "ic| expert_mask: tensor([[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "                          [0, 0, 0, 1, 0, 0, 1, 0, 1, 0]],\n",
      "                 \n",
      "                         [[0, 0, 1, 0, 1, 1, 0, 0, 1, 0],\n",
      "                          [1, 0, 0, 0, 0, 0, 0, 1, 0, 1]],\n",
      "                 \n",
      "                         [[1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
      "                          [0, 1, 1, 0, 1, 1, 0, 0, 0, 0]],\n",
      "                 \n",
      "                         [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "                          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([2, 5, 64])\n",
      "输出形状: torch.Size([2, 5, 64])\n",
      "路由器logits形状: torch.Size([10, 4])\n",
      "前向传播完成!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from icecream import ic\n",
    "\n",
    "# 简化的专家网络定义\n",
    "class BasicExpert(nn.Module):\n",
    "    # 一个 Expert 可以是一个最简单的 linear 层\n",
    "    # 也可以是 MLP 层\n",
    "    # 也可以是更复杂的 MLP 层（active function 设置为 swiglu）\n",
    "    def __init__(self, feature_in, feature_out):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_in, feature_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class Qwen3MoeSparseMoeBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_experts = config.num_experts  # 专家网络数量\n",
    "        self.top_k = config.num_experts_per_tok  # 每个token使用的专家数\n",
    "        self.norm_topk_prob = config.norm_topk_prob  # 是否对top_k权重进行归一化\n",
    "\n",
    "        # 门控网络：决定每个token应该被分配到哪个专家\n",
    "        self.gate = nn.Linear(config.hidden_size, config.num_experts, bias=False)\n",
    "        # 创建多个专家网络（使用简化的BasicExpert）\n",
    "        self.experts = nn.ModuleList(\n",
    "            [BasicExpert(config.hidden_size, config.hidden_size) for _ in range(self.num_experts)]\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"稀疏混合专家模型前向传播\"\"\"\n",
    "        batch_size, sequence_length, hidden_dim = hidden_states.shape\n",
    "        # 将输入展平: (batch_size, sequence_length, hidden_dim) -> (batch_size*sequence_length, hidden_dim)\n",
    "        hidden_states = hidden_states.view(-1, hidden_dim)\n",
    "        \n",
    "        # 计算路由logits: (batch*sequence_length, n_experts)\n",
    "        router_logits = self.gate(hidden_states)\n",
    "\n",
    "        # 通过softmax计算每个专家对每个token的权重\n",
    "        routing_weights = F.softmax(router_logits, dim=1, dtype=torch.float)\n",
    "        # 选择权重最高的top_k个专家\n",
    "        routing_weights, selected_experts = torch.topk(routing_weights, self.top_k, dim=-1)\n",
    "        \n",
    "        # 如果启用归一化，对top_k权重进行归一化\n",
    "        if self.norm_topk_prob:\n",
    "            routing_weights /= routing_weights.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # 将权重转换回输入的数据类型\n",
    "        routing_weights = routing_weights.to(hidden_states.dtype)\n",
    "\n",
    "        # 初始化最终输出张量\n",
    "        final_hidden_states = torch.zeros(\n",
    "            (batch_size * sequence_length, hidden_dim), dtype=hidden_states.dtype, device=hidden_states.device\n",
    "        )\n",
    "\n",
    "        # 创建专家掩码：使用one-hot编码标记每个token选择了哪些专家\n",
    "        # 形状: (n_experts, top_k, batch*sequence_length)\n",
    "        expert_mask = torch.nn.functional.one_hot(selected_experts, num_classes=self.num_experts).permute(2, 1, 0)\n",
    "        ic(expert_mask.shape)\n",
    "        ic(expert_mask)\n",
    "\n",
    "        # 找出至少被一个token选中的专家（活跃专家）\n",
    "        expert_hit = torch.greater(expert_mask.sum(dim=(-1, -2)), 0).nonzero()\n",
    "        \n",
    "        # 遍历所有被激活的专家\n",
    "        for expert_idx in expert_hit:\n",
    "            expert_layer = self.experts[expert_idx]  # 获取当前专家网络\n",
    "            \n",
    "            # 找出选择当前专家的所有token及其在top_k中的位置\n",
    "            idx, top_x = torch.where(expert_mask[expert_idx].squeeze(0))\n",
    "\n",
    "            # 提取对应token的隐藏状态并通过专家网络处理\n",
    "            current_state = hidden_states[None, top_x].reshape(-1, hidden_dim)\n",
    "            current_hidden_states = expert_layer(current_state) * routing_weights[top_x, idx, None]\n",
    "\n",
    "            # 将当前专家的计算结果累加到最终输出中\n",
    "            final_hidden_states.index_add_(0, top_x, current_hidden_states.to(hidden_states.dtype))\n",
    "        \n",
    "        # 恢复输出形状: (batch_size*sequence_length, hidden_dim) -> (batch_size, sequence_length, hidden_dim)\n",
    "        final_hidden_states = final_hidden_states.reshape(batch_size, sequence_length, hidden_dim)\n",
    "        return final_hidden_states, router_logits  # 返回输出和路由logits\n",
    "\n",
    "# 创建一个简单的配置类用于测试\n",
    "class SimpleConfig:\n",
    "    def __init__(self):\n",
    "        self.num_experts = 4\n",
    "        self.num_experts_per_tok = 2\n",
    "        self.norm_topk_prob = True\n",
    "        self.hidden_size = 64\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建配置和模型\n",
    "    config = SimpleConfig()\n",
    "    model = Qwen3MoeSparseMoeBlock(config)\n",
    "    \n",
    "    # 生成随机输入数据\n",
    "    batch_size, seq_len, hidden_size = 2, 5, config.hidden_size\n",
    "    dummy_input = torch.randn(batch_size, seq_len, hidden_size)\n",
    "    \n",
    "    print(\"输入形状:\", dummy_input.shape)\n",
    "    \n",
    "    # 前向传播\n",
    "    output, router_logits = model(dummy_input)\n",
    "    \n",
    "    print(\"输出形状:\", output.shape)\n",
    "    print(\"路由器logits形状:\", router_logits.shape)\n",
    "    print(\"前向传播完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamafactory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

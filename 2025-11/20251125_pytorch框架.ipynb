{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2672f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2025-11-25 13:33:18 Tuesday first time create\n",
    "\n",
    "\n",
    "参考 https://docs.pytorch.ac.cn/docs/stable/generated/torch.nn.Module.html，\n",
    "\n",
    "借助 https://deepwiki.com/search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb70f00",
   "metadata": {},
   "source": [
    "### get_submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bf3164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=20, bias=True)\n",
      "Linear(in_features=20, out_features=5, bias=True)\n",
      "Linear(in_features=5, out_features=2, bias=True)\n",
      "MyNet(\n",
      "  (block1): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (block2): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(20, 5)\n",
    "            )\n",
    "        )\n",
    "        self.block2 = nn.Linear(5, 2)\n",
    "\n",
    "model = MyNet()\n",
    "\n",
    "# ----------------------------\n",
    "# 获取子模块\n",
    "# ----------------------------\n",
    "m1 = model.get_submodule(\"block1.0\")     # 第一个 Linear\n",
    "m2 = model.get_submodule(\"block1.2.0\")   # 嵌套 Sequential 中的 Linear\n",
    "m3 = model.get_submodule(\"block2\")       # 直接拿到 block2\n",
    "\n",
    "m4 = model.get_submodule(\"\")\n",
    "print(m1)   # Linear(10 → 20)\n",
    "print(m2)   # Linear(20 → 5)\n",
    "print(m3)   # Linear(5 → 2)\n",
    "print(m4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57103dd",
   "metadata": {},
   "source": [
    "### PyTorch 的 `state_dict` 包含什么？\n",
    "\n",
    "1. **`state_dict` 是模型可保存到 ckpt 的全部状态**，如：\n",
    "\n",
    "   ```python\n",
    "   torch.save(model.state_dict(), \"model.pth\")\n",
    "   ```\n",
    "\n",
    "2. **`state_dict` 只包含三类信息：**\n",
    "\n",
    "   * **Parameters**：可训练参数（权重、偏置）。\n",
    "   * **Buffers**：非训练状态（BN 均值方差、mask 等）。\n",
    "   * **extra_state**：通过 `get_extra_state()` 明确返回的自定义状态。\n",
    "\n",
    "除此之外，模型中的普通 Python 属性 **不会自动保存**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176744e",
   "metadata": {},
   "source": [
    "\n",
    "具体而言，\n",
    "### **类别 1：会保存进 state_dict 且会被 optimizer 优化（Parameters）**\n",
    "\n",
    "1. 属于：\n",
    "\n",
    "* `nn.Parameter`\n",
    "* 模块里的可训练权重（权重 weight、偏置 bias）\n",
    "\n",
    "2. 特点：\n",
    "\n",
    "* 会自动进入 `state_dict()`\n",
    "* 会被优化器更新（Adam、SGD）\n",
    "* `.requires_grad = True`\n",
    "* optimizer.state_dict() 中也会保存对应的动量等信息\n",
    "\n",
    "3. 示例：\n",
    "\n",
    "  ```python\n",
    "  self.fc1 = nn.Linear(10, 20)\n",
    "  ```\n",
    "\n",
    "  进入 state_dict：\n",
    "\n",
    "  ```\n",
    "  fc1.weight\n",
    "  fc1.bias\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **类别 2：保存进 state_dict 但不会被 optimizer 优化（Buffers）**\n",
    "\n",
    "1.  属于：\n",
    "\n",
    "* 使用 `register_buffer(name, tensor)` 添加的状态\n",
    "* 例如：BN 中\n",
    "\n",
    "  * running_mean\n",
    "  * running_var\n",
    "\n",
    "2.  特点：\n",
    "\n",
    "* 会进入 `state_dict()`（自动）\n",
    "* **不会有梯度**\n",
    "* **不会被 optimizer 更新**\n",
    "* 仍然会在 `.to(device)` 中迁移设备\n",
    "\n",
    "3. 示例：\n",
    "\n",
    "```python\n",
    "self.register_buffer(\"running_scale\", torch.tensor(1.0))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **类别 3：保存到 state_dict[\"extra_state\"] 的自定义状态（Extra State）**\n",
    "\n",
    "1. 属于：\n",
    "\n",
    "你自己在模型中定义的“其他信息”，通过：\n",
    "\n",
    "```python\n",
    "def get_extra_state(self):\n",
    "    return {...}\n",
    "\n",
    "def set_extra_state(self, state):\n",
    "    ...\n",
    "```\n",
    "\n",
    "2. 特点：\n",
    "\n",
    "* 会作为 **extra_state** 统一进入 `state_dict`\n",
    "* 不属于参数，不属于 buffer\n",
    "* 适用于 Python 对象、配置、统计量等\n",
    "\n",
    "3. 示例：\n",
    "\n",
    "```python\n",
    "def get_extra_state(self):\n",
    "    return {\"scale\": self.custom_scale}\n",
    "```\n",
    "\n",
    "保存后 state_dict 结构：\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"fc1.weight\": ...,\n",
    "  \"fc1.bias\": ...,\n",
    "  \"running_scale\": ...,\n",
    "  \"extra_state\": {\"scale\": 999}\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### ✅ **最终：PyTorch state_dict 的三大类别**\n",
    "\n",
    "| 类别                    | 会进 state_dict        | 被 optimizer 更新 | 定义方式                      | 适用内容                  |\n",
    "| --------------------- | -------------------- | -------------- | ------------------------- | --------------------- |\n",
    "| **1. 参数（Parameters）** | ✔                    | ✔              | `nn.Parameter` / 层.weight | 权重、偏置                 |\n",
    "| **2. Buffer**         | ✔                    | ❌              | `register_buffer`         | BN 统计量、mask、pos_embed |\n",
    "| **3. Extra State**    | ✔（在 \"extra_state\" 中） | ❌              | `get_extra_state()`       | 自定义信息、Python 对象       |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

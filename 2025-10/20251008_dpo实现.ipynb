{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77910d2",
   "metadata": {},
   "source": [
    "## DPO代码实现\n",
    "\n",
    "\n",
    "DPO 损失函数形式：\n",
    "    $$L_{\\text{DPO}}(\\theta) = - \\mathbb{E}_{(x, y^+, y^-)} \\left[\n",
    "    \\log \\sigma\\left(\n",
    "    \\beta \\cdot \\left(\n",
    "    \\log\\frac{\\pi_\\theta(y^+|x)}{\\pi_\\text{ref}(y^+|x)} - \\log \\frac{\\pi_{\\theta}(y^-|x)}{\\pi_{\\text{ref}}(y^-|x)} \n",
    "    \\right)\n",
    "    \\right)\n",
    "    \\right]$$\n",
    "\n",
    "\n",
    "其中：\n",
    "\n",
    "- $\\pi_\\theta$：正在训练的语言模型；\n",
    "- $\\pi_{\\text{ref}}$：参考模型（通常是SFT模型）；\n",
    "- $\\beta$：温度系数，控制对偏好的敏感程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9071d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/trl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mpairs\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m51\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mpairs\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m56\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247mpairs\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m43\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m22\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mlabels\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247munsqueeze\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m21\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mseq_logps\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mlabels\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247munsqueeze\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m21\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mseq_logps\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: DPO loss = 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mlabels\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247munsqueeze\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m21\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mseq_logps\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mlabels\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247munsqueeze\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m21\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mseq_logps\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: DPO loss = 0.4389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mlabels\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247munsqueeze\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m21\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mseq_logps\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mlabels\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247munsqueeze\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;36m2\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m21\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mseq_logps\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m6\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: DPO loss = 0.7623\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from icecream import ic\n",
    "\n",
    "# ========== 初始化 GPT2 模型 ==========\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "ref_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "ref_model.eval()  # 参考模型不更新\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.model_max_length = 512 \n",
    "\n",
    "# ========== 构造假的DPO输入 ==========\n",
    "# 每个prompt有 chosen / rejected 各一条\n",
    "prompts = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain quantum entanglement simply.\",\n",
    "    \"Write a short poem about rain.\"\n",
    "]\n",
    "chosens = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Quantum entanglement means two particles stay linked no matter the distance.\",\n",
    "    \"Rain falls softly, painting the world anew.\"\n",
    "]\n",
    "rejecteds = [\n",
    "    \"France is a country.\",\n",
    "    \"Quantum is physics.\",\n",
    "    \"Rain is wet.\"\n",
    "]\n",
    "\n",
    "# 拼接 (chosen, rejected)\n",
    "pairs = []\n",
    "for p, c, r in zip(prompts, chosens, rejecteds):\n",
    "    pairs.append(p + \" \" + c)\n",
    "    pairs.append(p + \" \" + r)\n",
    "    ic(len(pairs[-1]))\n",
    "\n",
    "encodings = tokenizer(\n",
    "    pairs, padding=True, truncation=True, return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "input_ids = encodings.input_ids\n",
    "attention_mask = encodings.attention_mask\n",
    "\n",
    "ic(input_ids.shape)\n",
    "\n",
    "# ========= 定义DPO核心逻辑 =========\n",
    "def dpo_loss(policy_logps, ref_logps, beta=0.1):\n",
    "    chosen = policy_logps[0::2]\n",
    "    rejected = policy_logps[1::2]\n",
    "    ref_chosen = ref_logps[0::2]\n",
    "    ref_rejected = ref_logps[1::2]\n",
    "    logits = (chosen - rejected) - (ref_chosen - ref_rejected)\n",
    "    return -F.logsigmoid(beta * logits).mean()\n",
    "\n",
    "def get_logps(model, input_ids, attention_mask):\n",
    "    \"\"\"返回每个样本的 log π(y|x),即交叉熵\"\"\"\n",
    "    # with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits[:, :-1, :]\n",
    "    labels = input_ids[:, 1:]\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    # ic(log_probs.shape)     #log_probs.shape: torch.Size([6, 21, 50257])\n",
    "    ic(labels.unsqueeze(2).shape)\n",
    "    token_logps = torch.gather(log_probs, 2, labels.unsqueeze(2)).squeeze(2)\n",
    "    # ic(token_logps.shape)       #token_logps.shape: torch.Size([6, 21])\n",
    "    # ic(attention_mask.shape)        #attention_mask.shape: torch.Size([6, 22])\n",
    "    seq_logps = (token_logps * attention_mask[:, 1:]).sum(dim=1)\n",
    "    ic(seq_logps.shape)\n",
    "    return -seq_logps\n",
    "\n",
    "# ========= 优化器与训练 =========\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
    "beta = 0.1\n",
    "\n",
    "for step in range(3):\n",
    "    # 计算策略与参考模型 log π(y|x)\n",
    "    model.train()\n",
    "    policy_logps=get_logps(model,input_ids,attention_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ref_logps = get_logps(ref_model, input_ids, attention_mask)\n",
    "\n",
    "    # DPO loss\n",
    "    loss = dpo_loss(policy_logps, ref_logps, beta)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    print(f\"Step {step}: DPO loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca36d9f",
   "metadata": {},
   "source": [
    "## 交叉熵的计算细节\n",
    "\n",
    "1. **`logits[:, :-1, :]` 和 `labels = input_ids[:, 1:]` 的错位切片操作**\n",
    "\n",
    "    是因为模型在每个位置上都使用前面所有 token 作为条件，去预测下一个 token。\n",
    "\n",
    "\n",
    "    假设原始输入序列 input_ids 为 [x₁, x₂, x₃, x₄]（长度为 4），切片后：\n",
    "\n",
    "    - 模型输出截断（logits [:, :-1, :]）：取所有样本、除最后一个 token 外的所有位置，得到 [x₁, x₂, x₃]（长度为 3）。这部分是模型的 “预测输入上下文”，用于生成对下一个 token 的预测。\n",
    "\n",
    "    - 目标标签偏移（labels = input_ids [:, 1:]）：取所有样本、从第二个 token 开始的所有位置，得到 [x₂, x₃, x₄]（长度为 3）。这部分是模型的 “真实目标”，每个位置的标签对应前序上下文要预测的 token。\n",
    "\n",
    "\n",
    "\n",
    "2. **负号 `-seq_logps`**\n",
    "\n",
    "    在语言模型训练中，我们最小化的交叉熵损失：\n",
    "    $$\\mathcal{L}_{CE} = - \\sum_t \\log P_\\theta(x_t | x_{<t})$$\n",
    "    即交叉熵（Cross-Entropy）就是负的 token 级对数似然（Negative Log-Likelihood, NLL）。\n",
    "    故而，本质上等价于**最大化每个 token 的对数似然**（log-likelihood）。\n",
    "    所以在代码中返回 `-seq_logps`，\n",
    "\n",
    "\n",
    "代码实现：\n",
    "```python\n",
    "def get_logps(model, input_ids, attention_mask):\n",
    "    \"\"\"返回每个样本的 log π(y|x),即交叉熵\"\"\"\n",
    "    # with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits[:, :-1, :]\n",
    "    labels = input_ids[:, 1:]\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    # ic(log_probs.shape)     #log_probs.shape: torch.Size([6, 21, 50257])\n",
    "    token_logps = torch.gather(log_probs, 2, labels.unsqueeze(2)).squeeze(2)\n",
    "    # ic(token_logps.shape)       #token_logps.shape: torch.Size([6, 21])\n",
    "    # ic(attention_mask.shape)        #attention_mask.shape: torch.Size([6, 22])\n",
    "    seq_logps = (token_logps * attention_mask[:, 1:]).sum(dim=1)\n",
    "    return -seq_logps\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cb1b21",
   "metadata": {},
   "source": [
    "## reward model的训练过程\n",
    "2025-10-04 23:50:24 Saturday\n",
    "\n",
    "参考 https://blog.csdn.net/shizheng_Li/article/details/145947974\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ef700",
   "metadata": {},
   "source": [
    "\n",
    "## 1. 应用场景\n",
    "\n",
    "训练一个 **Reward Model ($R_\\phi(x, y)$)**，用于评估模型输出 (y) 对输入 (x) 的“人类偏好得分”。\n",
    "在强化学习阶段（如 **PPO/GRPO**）中提供奖励信号。\n",
    "\n",
    "\n",
    "## 2. 实现方式\n",
    "\n",
    "* **模型结构**\n",
    "  复用经过 SFT 的语言模型骨干（已具备较好语言理解能力），\n",
    "  将原本的 *下一词预测头*（LM Head）替换为 **回归头**（输出单个标量 reward 值）。\n",
    "\n",
    "* **训练数据结构**\n",
    "  每个样本包含一对人类偏好：\n",
    "  $(x, y^+, y^-)$\n",
    "  其中：\n",
    "\n",
    "  * (x)：prompt（问题/输入）\n",
    "  * ($y^+$)：更优回答（human preferred）\n",
    "  * ($y^-$)：较差回答（human rejected）\n",
    "\n",
    "* **损失函数（Bradley–Terry 形式）**\n",
    "  $$L(\\phi) = -\\mathbb{E}\\big[\\log \\sigma(R_\\phi(x, y^+) - R_\\phi(x, y^-))\\big]$$\n",
    "  目标是最大化 $(R_\\phi(x, y^+) > R_\\phi(x, y^-))$ 的概率。\n",
    "\n",
    "\n",
    "\n",
    "## 3. 训练流程总结\n",
    "\n",
    "1. **加载预训练的 SFT 模型**\n",
    "   （具备较好语言理解与生成能力）\n",
    "2. **替换输出层** → 线性回归头（1个神经元输出 reward）\n",
    "3. **构造偏好数据对** ((x, $y^+, y^-$))\n",
    "4. **拼接输入**：“`x + y`” 作为模型输入，reward 对应整个回答\n",
    "5. **前向计算** 得到 $(R(x, y^+))、(R(x, y^-))$\n",
    "6. **计算对比损失**（希望 better > worse）\n",
    "7. **反向传播 + 优化参数**\n",
    "\n",
    "\n",
    "## 4.reward model的训练代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m26\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m26\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m20\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m20\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 2.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m26\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m26\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m20\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m20\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 1.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m26\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m26\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m20\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m20\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m15\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247minput_ids_tensor\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n",
      "\u001b[38;5;245m    \u001b[39m\u001b[38;5;247mattention_mask\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mshape\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mtorch\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mSize\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m13\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss = 0.6366\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from icecream import ic\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载 tokenizer 并确保 pad_token 存在（GPT2 等可能没有）\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, tokenizer, model_name='gpt2', device=None):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device or torch.device('cpu')\n",
    "        self.backbone = AutoModel.from_pretrained(model_name).to(self.device)       ##假设为已经有的sft模型\n",
    "        self.reward_head = nn.Linear(self.backbone.config.hidden_size, 1).to(self.device)\n",
    "\n",
    "    def forward(self, prompt: str, response: str):\n",
    "        prompt_ids = self.tokenizer.encode(prompt, add_special_tokens=False)\n",
    "        response_ids = self.tokenizer.encode(response, add_special_tokens=False)\n",
    "        sep = self.tokenizer.eos_token_id if self.tokenizer.eos_token_id is not None else None\n",
    "        if sep is not None:\n",
    "            input_ids = prompt_ids + [sep] + response_ids\n",
    "            prompt_len = len(prompt_ids) + 1\n",
    "        else:\n",
    "            input_ids = prompt_ids + response_ids\n",
    "            prompt_len = len(prompt_ids)\n",
    "\n",
    "        # 截断到模型支持的最大长度（从右侧保留 response 的结尾）\n",
    "        max_len = getattr(self.backbone.config, 'n_positions', None) or getattr(self.backbone.config, 'max_position_embeddings', None)\n",
    "        if max_len is not None and len(input_ids) > max_len:\n",
    "            excess = len(input_ids) - max_len\n",
    "            input_ids = input_ids[excess:]\n",
    "            prompt_len = max(0, prompt_len - excess)\n",
    "\n",
    "        input_ids_tensor = torch.tensor([input_ids], dtype=torch.long, device=self.device)\n",
    "        attention_mask = torch.ones_like(input_ids_tensor, device=self.device)\n",
    "        ic(input_ids_tensor.shape,attention_mask.shape)\n",
    "        outputs = self.backbone(input_ids=input_ids_tensor, attention_mask=attention_mask, return_dict=True)\n",
    "        last_hidden = outputs.last_hidden_state  # (B, L, D)\n",
    "\n",
    "        seq_len = last_hidden.size(1)\n",
    "        if prompt_len >= seq_len or prompt_len < 0:\n",
    "            pooled = last_hidden[:, -1, :]\n",
    "        else:\n",
    "            response_hidden = last_hidden[:, prompt_len:, :]\n",
    "            pooled = response_hidden.mean(dim=1)\n",
    "\n",
    "        reward = self.reward_head(pooled).squeeze(-1)\n",
    "        return reward\n",
    "\n",
    "# 简单示例数据（文本）\n",
    "samples = [\n",
    "    { 'prompt': 'Explain the concept of overfitting in machine learning.', \n",
    "     'chosen': 'Overfitting happens when a model learns noise instead of the true pattern.', \n",
    "     'rejected': 'It means the model trains too much.' },\n",
    "    { 'prompt': 'What is the capital of France?', \n",
    "     'chosen': 'The capital of France is Paris.',\n",
    "       'rejected': 'France is in Europe.' },\n",
    "]\n",
    "\n",
    "# 初始化模型与优化器\n",
    "model = RewardModel(tokenizer=tokenizer, model_name='gpt2', device=device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# 训练循环（仅作演示，样本很少）\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for sample in samples:\n",
    "        r_chosen = model(sample['prompt'], sample['chosen'])\n",
    "        r_rejected = model(sample['prompt'], sample['rejected'])\n",
    "        loss = -torch.log(torch.sigmoid(r_chosen - r_rejected)).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch}, Loss = {total_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97265a05",
   "metadata": {},
   "source": [
    "## 5.reward model的损失函数和 DPO很像，那两者有什么区别?\n",
    "\n",
    "两者只是形式上像，但是谁在被训练是不一样的。\n",
    "\n",
    "\n",
    "\n",
    "- Reward Model 用人类偏好数据 ((x, y^+, y^-)) 训练：\n",
    "    $$L_{\\text{RM}}(\\phi)\n",
    "    = - \\mathbb{E}_{(x, y^+, y^-)} \\left[\n",
    "    \\log \\sigma\\big(R_\\phi(x, y^+) - R_\\phi(x, y^-)\\big)\n",
    "    \\right]$$\n",
    "\n",
    "    其中：\n",
    "\n",
    "    * ($R_\\phi(x, y)$)：Reward Model 输出的分数；\n",
    "    * ($\\sigma(z) = 1 / (1 + e^{-z})$)：sigmoid；\n",
    "    * 优化参数是 **Reward Model 参数** $(\\phi)$。\n",
    "\n",
    "    ➡️ 损失的含义是让「更好」回答的得分高于「更差」回答。故而梯度更新的 ( $R_{\\phi}$ )；\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- DPO 损失函数形式：\n",
    "    $$L_{\\text{DPO}}(\\theta) = - \\mathbb{E}_{(x, y^+, y^-)} \\left[\n",
    "    \\log \\sigma\\left(\n",
    "    \\beta \\cdot \\left(\n",
    "    \\log\\frac{\\pi_\\theta(y^+|x)}{\\pi_\\text{ref}(y^+|x)} - \\log \\frac{\\pi_{\\theta}(y^-|x)}{\\pi_{\\text{ref}}(y^-|x)} \n",
    "    \\right)\n",
    "    \\right)\n",
    "    \\right]$$\n",
    "\n",
    "\n",
    "    其中：\n",
    "\n",
    "    * $(\\pi_\\theta$)：正在训练的语言模型；\n",
    "    * $(\\pi_{\\text{ref}})$：参考模型（通常是SFT模型）；\n",
    "    * $(\\beta)$：温度系数，控制对偏好的敏感程度。\n",
    "\n",
    "\n",
    "    ➡️ DPO是不需要显式地教一个模型打分了，而是直接优化生成模型，让它的输出顺序符合这些人类偏好。故而梯度更新的是$\\pi_{\\theta}$。\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

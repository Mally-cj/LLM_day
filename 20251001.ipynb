{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d824f4",
   "metadata": {},
   "source": [
    "\n",
    "## 扩散模型和LLM都是基于最大似然的原理吗？\n",
    "\n",
    "\n",
    "两者原理上都基于最大似然，只不过：\n",
    "  * LLM **直接最大化似然**。\n",
    "  * 扩散模型 **间接最大化似然（通过ELBO）**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bbf6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. LLM：标准的最大似然 (MLE)\n",
    "\n",
    "* 目标：最大化训练语料在模型下的对数似然\n",
    "  $\\max_\\theta \\sum_i \\log p_\\theta(x^{(i)})$\n",
    "* 在自回归形式下：\n",
    "  $$p_\\theta(x) = \\prod_{t=1}^T p_\\theta(x_t | x_{<t})$$\n",
    "* 实现：最小化 **交叉熵损失**，它和 MLE 完全等价。\n",
    "\n",
    "👉 所以 LLM = **纯粹的 MLE 训练**。\n",
    "\n",
    "\n",
    "### 2. 扩散模型：最大似然的变种（ELBO）\n",
    "\n",
    "* 目标同样是最大化 $(\\log p_\\theta(x_0))$。\n",
    "* 因为引入了隐变量（扩散的噪声过程），直接算难，于是用 **变分推断**：\n",
    "  $$\n",
    "  \\log p_\\theta(x_0) \\geq \\mathbb{E}*q \\Big[\\log \\frac{p*\\theta(x_{0:T})}{q(x_{1:T}|x_0)} \\Big]\n",
    "  $$\n",
    "  （这是 **ELBO**，证据下界）\n",
    "* 经过推导，最终训练目标可以简化为 **噪声预测的 MSE**：\n",
    "  $$\n",
    "  \\mathcal{L}(\\theta) = \\mathbb{E}*{x_0, \\epsilon, t} \\big[|\\epsilon - \\epsilon*\\theta(x_t, t)|^2\\big]\n",
    "  $$\n",
    "* 这个 MSE 损失表面上是“预测噪声”，但实际上是在最大化似然的下界。\n",
    "\n",
    "👉 所以扩散模型 = **基于似然的变分优化**（近似 MLE）。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54f334",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3.生成模型训练目标与似然关系\n",
    "\n",
    "| 模型类别      | 代表方法                                   | 训练目标                                    | 与最大似然的关系        | 特点              |\n",
    "| --------- | -------------------------------------- | --------------------------------------- | --------------- | --------------- |\n",
    "| **直接似然**  | **LLM (GPT, BERT 预训练)**                | 最小化交叉熵（等价于最大化对数似然）                      | ✅ 完全等价 MLE      | 离散自回归，逐 token   |\n",
    "| **变分似然**  | **VAE**                                | 最大化 ELBO（证据下界）                          | ✅ 近似 MLE（下界）    | 采样快但生成模糊        |\n",
    "|           | **Diffusion (DDPM, Stable Diffusion)** | 噪声预测 MSE（由 ELBO 推导）                     | ✅ 等价于最大似然下界     | 全局逐步去噪，采样慢但质量高  |\n",
    "|           | **Flow-based (Glow, RealNVP)**         | 负对数似然（Jacobian + base 分布）               | ✅ 精确 MLE        | 可逆映射，采样快但表达力有限  |\n",
    "| **非似然**   | **GAN (StyleGAN, DCGAN)**              | 对抗损失（判别器 vs 生成器）                        | ❌ 不涉及似然         | 生成质量高，但不稳定、模式崩溃 |\n",
    "| **混合/近似** | **EBM (能量模型)**                         | Score Matching / Contrastive Divergence | ⚠️ 与似然相关，但需近似推断 | 训练难，需要 MCMC 采样  |\n",
    "|           | **对比学习 (word2vec, SimCLR)**            | 噪声对比估计 (NCE) / InfoNCE                  | ⚠️ 近似似然估计       | 训练高效，但依赖负样本设计   |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "总结： **LLM 和 Flow 属于显式似然建模，VAE 和 Diffusion 属于近似似然建模，GAN 属于非似然建模，而 EBM/对比学习则处于中间。**\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
